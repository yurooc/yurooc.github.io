[{"content":"Ajax面试题 1什么是ajax？ajax作用是什么？ AJAX = 异步 JavaScript 和 XML。 AJAX 是一种用于创建快速动态网页的技术。 通过在后台与服务器进行少量数据交换,AJAX 可以使网页实现异步更新.\n2、为什么要用ajax：\nAjax应用程序的优势在于：\n通过异步模式，提升了用户体验 优化了浏览器和服务器之间的传输，减少不必要的数据往返，减少了带宽占用 Ajax引擎在客户端运行，承担了一部分本来由服务器承担的工作，从而减少了大用户量下的服务器负载。 3.AJAX最大的特点是什么。 Ajax可以实现动态不刷新（局部刷新） 就是能在不更新整个页面的前提下维护数据。这使得Web应用程序更为迅捷地回应用户动作，并避免了在网络上发送那些没有改变过的信息。\n4、请介绍一下XMLHttprequest对象。 Ajax的核心是JavaScript对象XmlHttpRequest。该对象在Internet Explorer 5中首次引入，它是一种支持异步请求的技术。简而言之，XmlHttpRequest使您可以使用JavaScript向服务器提出请求并处理响应，而不阻塞用户。通过XMLHttpRequest对象，Web开发人员可以在页面加载以后进行页面的局部更新。 5、AJAX技术体系的组成部分有哪些。 HTML，css，dom，xml，xmlHttpRequest，javascript\n6:原生js ajax请求有几个步骤？分别是什么 //创建 XMLHttpRequest 对象 var ajax = new XMLHttpRequest(); //规定请求的类型、URL 以及是否异步处理请求。 ajax.open(\u0026#39;GET\u0026#39;,url,true); //发送信息至服务器时内容编码类型 ajax.setRequestHeader(\u0026#34;Content-type\u0026#34;, \u0026#34;application/x-www-form-urlencoded\u0026#34;); //发送请求 ajax.send(null); //接受服务器响应数据 ajax.onreadystatechange = function () { if (obj.readyState == 4 \u0026amp;\u0026amp; (obj.status == 200 || obj.status == 304)) { } }; 7:json字符串转换集json对象、json对象转换json字符串\n//字符串转对象\nJSON.parse(json)\neval(\u0026rsquo;(\u0026rsquo; + jsonstr + \u0026lsquo;)\u0026rsquo;)\n// 对象转字符串\nJSON.stringify(json)\nEval() json.parse()区别？？？？\n第一种方式：eval（）；\nvar data=\u0026rsquo;{\u0026ldquo;student\u0026rdquo;：[{\u0026ldquo;name\u0026rdquo;:\u0026ldquo;张三\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:\u0026ldquo;11\u0026rdquo;}，{\u0026ldquo;name\u0026rdquo;:\u0026ldquo;李四\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:\u0026ldquo;11\u0026rdquo;},{\u0026ldquo;name\u0026rdquo;:\u0026ldquo;王五\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:\u0026ldquo;11\u0026rdquo;}]}’；\neval（’（“+data+”）’）;\n第二种方式：JSON.parse（）；\nvar data=\u0026rsquo;{\u0026ldquo;student\u0026rdquo;：[{\u0026ldquo;name\u0026rdquo;:\u0026ldquo;张三\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:\u0026ldquo;11\u0026rdquo;}，{\u0026ldquo;name\u0026rdquo;:\u0026ldquo;李四\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:\u0026ldquo;11\u0026rdquo;},{\u0026ldquo;name\u0026rdquo;:\u0026ldquo;王五\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:\u0026ldquo;11\u0026rdquo;}]}’；\nJSON.parse（data）；\n区别：eval方法不会去检查给的字符串时候符合json的格式~同时如果给的字符串中存在js代码eval也会一并执行~比如:\nvar data=\u0026rsquo;{\u0026ldquo;student\u0026rdquo;：[{\u0026ldquo;name\u0026rdquo;:\u0026ldquo;张三\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:\u0026ldquo;11\u0026rdquo;}，{\u0026ldquo;name\u0026rdquo;:\u0026ldquo;李四\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:\u0026ldquo;alert(11)\u0026rdquo;},{\u0026ldquo;name\u0026rdquo;:\u0026ldquo;王五\u0026rdquo;,\u0026ldquo;age\u0026rdquo;:\u0026ldquo;11\u0026rdquo;}]}’；\n此时执行eval方法后会先弹出一个提示框输出11的字符串;\n这时候使用JSON.parse()就会报错,显示错误信息为当前字符串不符合json格式;即JSON.parse()方法会检查需要转换的字符串是否符合json格式.\n相比而言eval方法是很不安全，特别是当涉及到第三方时我们需要确保传给eval的参数是我们可以控制的，不然里面插入比如window.location~指向一个恶意的连接\n总的来说，还是推荐使用JSON.parse来实现json格式字符串的解析。\n8.什么是JSON？ JSON是一种轻量级的数据交换格式。\n9:ajax几种请求方式？他们的优缺点？ 常用的post,get,delete put\n###代码上的区别 1:get通过url传递参数 2:post设置请求头 规定请求数据类型 ###使用上的区别 1:post比get安全 (因为post参数在请求体中。get参数在url上面) 2:get传输速度比post快 根据传参决定的。 (post通过请求体传参，后台通过数据流接收。速度稍微慢一些。而get通过url传参可以直接获取) 3:post传输文件大理论没有限制 get传输文件小大概7-8k ie4k左右 4:get获取数据 post上传数据 (上传的数据比较多 而且上传数据都是重要数据。所以不论在安全性还是数据量级 post是最好的选择) 10.什么情况造成跨域？ 同源策略限制 不同源会造成跨域。以下任意一种情况不同，都是不同源。\n同源：协议 域名 端口号全部相同 只要有一个不相同就是非同源策略\n11.跨域解决方案有哪些？ 原理：动态创建一个script标签。利用script标签的src属性不受同源策略限制。因为所有的src属性和href属性都不受同源策略限制。可以请求第三方服务器数据内容。\n步骤：\n去创建一个script标签 script的src属性设置接口地址 接口参数,必须要带一个自定义函数名 要不然后台无法返回数据。 通过定义函数名去接收后台返回数据 //去创建一个script标签 var script = document.createElement(\u0026#34;script\u0026#34;); //script的src属性设置接口地址 并带一个callback回调函数名称 script.src = \u0026#34;http://127.0.0.1:8888/index.php?callback=jsonpCallback\u0026#34;; //插入到页面 document.head.appendChild(script); //通过定义函数名去接收后台返回数据function jsonpCallback(data){ //注意 jsonp返回的数据是json对象可以直接使用 //ajax 取得数据是json字符串需要转换成json对象才可以使用。 } CORS：跨域资源共享 原理：服务器设置Access-Control-Allow-OriginHTTP响应头之后，浏览器将会允许跨域请求\n限制：浏览器需要支持HTML5，可以支持POST，PUT等方法兼容ie9以上\n需要后台设置 Access-Control-Allow-Origin: * //允许所有域名访问，或者 Access-Control-Allow-Origin: http://a.com //只允许所有域名访问 3.反向代理\n4.window+iframe\n15 介绍一下XMLHttpRequest对象的常用方法和属性 open(“method”,”URL”) 建立对服务器的调用，第一个参数是HTTP请求 方式可以为GET，POST或任何服务器所支持的您想调用的方式。 第二个参数是请求页面的URL。 send()方法，发送具体请求 abort()方法，停止当前请求 readyState属性 请求的状态 有5个可取值0=未初始化 ，1=正在加载 2=以加载，3=交互中，4=完成 responseText 属性 服务器的响应，表示为一个串 reponseXML 属性 服务器的响应，表示为XML status 服务器的HTTP状态码，200对应ok 400对应not found\n16什么是XML XML是扩展标记语言，能够用一系列简单的标记描述数据\n17.AJAX都有哪些优点和缺点？ 1、最大的一点是页面无刷新，用户的体验非常好。 2、使用异步方式与服务器通信，具有更加迅速的响应能力。 3、可以把以前一些服务器负担的工作转嫁到客户端，利用客户端闲置的能力来处理，减轻服务器和带宽的负担，节约空间和宽带租用成本。并且减轻服务器的负担，ajax的原则是“按需取数据”，可以最大程度的减少冗余请求，和响应对服务器造成的负担。 4、基于标准化的并被广泛支持的技术，不需要下载插件或者小程序。\najax的缺点 1、ajax不支持浏览器back按钮。 2、安全问题 AJAX暴露了与服务器交互的细节。 3、对搜索引擎的支持比较弱。 4、破坏了程序的异常机制。 5、不容易调试。\n","permalink":"https://yurooc.github.io/blog/ajax%E9%9D%A2%E8%AF%95%E9%A2%98/","summary":"Ajax面试题 1什么是ajax？ajax作用是什么？ AJAX = 异步 JavaScript 和 XML。 AJAX 是一种用于创建快速动态网页的技术。 通过在后台与服务器进行少量数据交","title":"Ajax面经"},{"content":"什么是MySQL MySQL是一个关系型数据库，它采用表的形式来存储数据。你可以理解成是Excel表格，既然是表的形式存储数据，就有表结构（行和列）。行代表每一行数据，列代表该行中的每个值。列上的值是有数据类型的，比如：整数、字符串、日期等等。\n事务的四大特性？ 事务特性ACID：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。\n原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚。 一致性是指一个事务执行之前和执行之后都必须处于一致性状态。比如a与b账户共有1000块，两人之间转账之后无论成功还是失败，它们的账户总和还是1000。 隔离性。跟隔离级别相关，如read committed，一个事务只能读到已经提交的修改。 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 数据库的三大范式 第一范式1NF\n确保数据库表字段的原子性。\n比如字段 userInfo: 广东省 10086' ，依照第一范式必须拆分成 userInfo: 广东省 userTel: 10086两个字段。\n第二范式2NF\n首先要满足第一范式，另外包含两部分内容，一是表必须有一个主键；二是非主键列必须完全依赖于主键，而不能只依赖于主键的一部分。\n举个例子。假定选课关系表为student_course(student_no, student_name, age, course_name, grade, credit)，主键为(student_no, course_name)。其中学分完全依赖于课程名称，姓名年龄完全依赖学号，不符合第二范式，会导致数据冗余（学生选n门课，姓名年龄有n条记录）、插入异常（插入一门新课，因为没有学号，无法保存新课记录）等问题。\n应该拆分成三个表：学生：student(stuent_no, student_name, 年龄)；课程：course(course_name, credit)；选课关系：student_course_relation(student_no, course_name, grade)。\n第三范式3NF\n首先要满足第二范式，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。\n假定学生关系表为Student(student_no, student_name, age, academy_id, academy_telephone)，主键为\u0026quot;学号\u0026quot;，其中学院id依赖于学号，而学院地点和学院电话依赖于学院id，存在传递依赖，不符合第三范式。\n可以把学生关系表分为如下两个表：学生：(student_no, student_name, age, academy_id)；学院：(academy_id, academy_telephone)。\n2NF和3NF的区别？\n2NF依据是非主键列是否完全依赖于主键，还是依赖于主键的一部分。 3NF依据是非主键列是直接依赖于主键，还是直接依赖于非主键。 事务隔离级别有哪些？ 先了解下几个概念：脏读、不可重复读、幻读。\n脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。 不可重复读是指在对于数据库中的某行记录，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，另一个事务修改了数据并提交了。 幻读是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录。对幻读的正确理解是一个事务内的读取操作的结论不能支撑之后业务的执行。假设事务要新增一条记录，主键为id，在新增之前执行了select，没有发现id为xxx的记录，但插入时出现主键冲突，这就属于幻读，读取不到记录却发现主键冲突是因为记录实际上已经被其他的事务插入了，但当前事务不可见。 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。\n事务隔离就是为了解决上面提到的脏读、不可重复读、幻读这几个问题。\nMySQL数据库为我们提供的四种隔离级别：\nSerializable (串行化)：通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。 Repeatable read (可重复读)：MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，解决了不可重复读的问题。 Read committed (读已提交)：一个事务只能看见已经提交事务所做的改变。可避免脏读的发生。 Read uncommitted (读未提交)：所有事务都可以看到其他未提交事务的执行结果。 查看隔离级别：\nselect @@transaction_isolation; 设置隔离级别：\nset session transaction isolation level read uncommitted; 生产环境数据库一般用的什么隔离级别呢？ 生产环境大多使用RC。为什么不是RR呢？\n可重复读(Repeatable Read)，简称为RR 读已提交(Read Commited)，简称为RC\n缘由一：在RR隔离级别下，存在间隙锁，导致出现死锁的几率比RC大的多！ 缘由二：在RR隔离级别下，条件列未命中索引会锁表！而在RC隔离级别下，只锁行!\n也就是说，RC的并发性高于RR。\n并且大部分场景下，不可重复读问题是可以接受的。毕竟数据都已经提交了，读出来本身就没有太大问题！\n互联网项目中mysql应该选什么事务隔离级别open in new window\n编码和字符集的关系 我们平时可以在编辑器上输入各种中文英文字母，但这些都是给人读的，不是给计算机读的，其实计算机真正保存和传输数据都是以二进制0101的格式进行的。\n那么就需要有一个规则，把中文和英文字母转化为二进制。其中d对应十六进制下的64，它可以转换为01二进制的格式。于是字母和数字就这样一一对应起来了，这就是ASCII编码格式。\n它用一个字节，也就是8位来标识字符，基础符号有128个，扩展符号也是128个。也就只能表示下英文字母和数字。\n这明显不够用。于是，为了标识中文，出现了GB2312的编码格式。为了标识希腊语，出现了greek编码格式，为了标识俄语，整了cp866编码格式。\n为了统一它们，于是出现了Unicode编码格式，它用了2~4个字节来表示字符，这样理论上所有符号都能被收录进去，并且它还完全兼容ASCII的编码，也就是说，同样是字母d，在ASCII用64表示，在Unicode里还是用64来表示。\n但不同的地方是ASCII编码用1个字节来表示，而Unicode用则两个字节来表示。\n同样都是字母d，unicode比ascii多使用了一个字节，如下：\nD ASCII: 01100100 D Unicode: 00000000 01100100 可以看到，上面的unicode编码，前面的都是0，其实用不上，但还占了个字节，有点浪费。如果我们能做到该隐藏时隐藏，这样就能省下不少空间，按这个思路，就是就有了UTF-8编码。\n总结一下，按照一定规则把符号和二进制码对应起来，这就是编码。而把n多这种已经编码的字符聚在一起，就是我们常说的字符集。\n比如utf-8字符集就是所有utf-8编码格式的字符的合集。\n想看下mysql支持哪些字符集。可以执行 show charset;\nutf8和utf8mb4的区别 上面提到utf-8是在unicode的基础上做的优化，既然unicode有办法表示所有字符，那utf-8也一样可以表示所有字符，为了避免混淆，我在后面叫它大utf8。\nmysql支持的字符集中有utf8和utf8mb4。\n先说utf8mb4编码，mb4就是most bytes 4的意思，从上图最右边的Maxlen可以看到，它最大支持用4个字节来表示字符，它几乎可以用来表示目前已知的所有的字符。\n再说mysql字符集里的utf8，它是数据库的默认字符集。但注意，此utf8非彼utf8，我们叫它小utf8字符集。为什么这么说，因为从Maxlen可以看出，它最多支持用3个字节去表示字符，按utf8mb4的命名方式，准确点应该叫它utf8mb3。\nutf8 就像是阉割版的utf8mb4，只支持部分字符。比如emoji表情，它就不支持。\n而mysql支持的字符集里，第三列，collation，它是指字符集的比较规则。\n比如，\u0026ldquo;debug\u0026quot;和\u0026quot;Debug\u0026quot;是同一个单词，但它们大小写不同，该不该判为同一个单词呢。\n这时候就需要用到collation了。\n通过SHOW COLLATION WHERE Charset = 'utf8mb4';可以查看到utf8mb4下支持什么比较规则。\n如果collation = utf8mb4_general_ci，是指使用utf8mb4字符集的前提下，挨个字符进行比较（general），并且不区分大小写（_ci，case insensitice）。\n这种情况下，\u0026ldquo;debug\u0026quot;和\u0026quot;Debug\u0026quot;是同一个单词。\n如果改成collation=utf8mb4_bin，就是指挨个比较二进制位大小。\n于是\u0026quot;debug\u0026quot;和\u0026quot;Debug\u0026quot;就不是同一个单词。\n那utf8mb4对比utf8有什么劣势吗？\n我们知道数据库表里，字段类型如果是char(2)的话，里面的2是指字符个数，也就是说不管这张表用的是什么编码的字符集，都能放上2个字符。\n而char又是固定长度，为了能放下2个utf8mb4的字符，char会默认保留2*4（maxlen=4）= 8个字节的空间。\n如果是utf8mb3，则会默认保留 2 * 3 (maxlen=3) = 6个字节的空间。也就是说，在这种情况下，utf8mb4会比utf8mb3多使用一些空间。\n索引 什么是索引？ 索引是存储引擎用于提高数据库表的访问速度的一种数据结构。它可以比作一本字典的目录，可以帮你快速找到对应的记录。\n索引一般存储在磁盘的文件中，它是占用物理空间的。\n索引的优缺点？ 优点：\n加快数据查找的速度 为用来排序或者是分组的字段添加索引，可以加快分组和排序的速度 加快表与表之间的连接 缺点：\n建立索引需要占用物理空间 会降低表的增删改的效率，因为每次对表记录进行增删改，需要进行动态维护索引，导致增删改时间变长 索引的作用？ 数据是存储在磁盘上的，查询数据时，如果没有索引，会加载所有的数据到内存，依次进行检索，读取磁盘次数较多。有了索引，就不需要加载所有数据，因为B+树的高度一般在2-4层，最多只需要读取2-4次磁盘，查询速度大大提升。\n什么情况下需要建索引？ 经常用于查询的字段 经常用于连接的字段建立索引，可以加快连接的速度 经常需要排序的字段建立索引，因为索引已经排好序，可以加快排序查询速度 什么情况下不建索引？ where条件中用不到的字段不适合建立索引 表记录较少。比如只有几百条数据，没必要加索引。 需要经常增删改。需要评估是否适合加索引 参与列计算的列不适合建索引 区分度不高的字段不适合建立索引，如性别，只有男/女/未知三个值。加了索引，查询效率也不会提高。 索引的数据结构 索引的数据结构主要有B+树和哈希表，对应的索引分别为B+树索引和哈希索引。InnoDB引擎的索引类型有B+树索引和哈希索引，默认的索引类型为B+树索引。\nB+树索引\nB+ 树是基于B 树和叶子节点顺序访问指针进行实现，它具有B树的平衡性，并且通过顺序访问指针来提高区间查询的性能。\n在 B+ 树中，节点中的 key 从左到右递增排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。\n进行查找操作时，首先在根节点进行二分查找，找到key所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出key所对应的数据项。\nMySQL 数据库使用最多的索引类型是BTREE索引，底层基于B+树数据结构来实现。\nmysql\u0026gt; show index from blog\\G; *************************** 1. row *************************** Table: blog Non_unique: 0 Key_name: PRIMARY Seq_in_index: 1 Column_name: blog_id Collation: A Cardinality: 4 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment: Index_comment: Visible: YES Expression: NULL 哈希索引\n哈希索引是基于哈希表实现的，对于每一行数据，存储引擎会对索引列进行哈希计算得到哈希码，并且哈希算法要尽量保证不同的列值计算出的哈希码值是不同的，将哈希码的值作为哈希表的key值，将指向数据行的指针作为哈希表的value值。这样查找一个数据的时间复杂度就是O(1)，一般多用于精确查找。\nHash索引和B+树索引的区别？ 哈希索引不支持排序，因为哈希表是无序的。 哈希索引不支持范围查找。 哈希索引不支持模糊查询及多列索引的最左前缀匹配。 因为哈希表中会存在哈希冲突，所以哈希索引的性能是不稳定的，而B+树索引的性能是相对稳定的，每次查询都是从根节点到叶子节点。 为什么B+树比B树更适合实现数据库索引？ 由于B+树的数据都存储在叶子结点中，叶子结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，而在数据库中基于范围的查询是非常频繁的，所以通常B+树用于数据库索引。 B+树的节点只存储索引key值，具体信息的地址存在于叶子节点的地址中。这就使以页为单位的索引中可以存放更多的节点。减少更多的I/O支出。 B+树的查询效率更加稳定，任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 索引有什么分类？ 1、主键索引：名为primary的唯一非空索引，不允许有空值。\n2、唯一索引：索引列中的值必须是唯一的，但是允许为空值。唯一索引和主键索引的区别是：唯一索引字段可以为null且可以存在多个null值，而主键索引字段不可以为null。唯一索引的用途：唯一标识数据库表中的每条记录，主要是用来防止数据重复插入。创建唯一索引的SQL语句如下：\nALTER TABLE table_name ADD CONSTRAINT constraint_name UNIQUE KEY(column_1,column_2,...); 3、组合索引：在表中的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，使用组合索引时需遵循最左前缀原则。\n4、全文索引：只能在CHAR、VARCHAR和TEXT类型字段上使用全文索引。\n5、普通索引：普通索引是最基本的索引，它没有任何限制，值可以为空。\n什么是最左匹配原则？ 如果 SQL 语句中用到了组合索引中的最左边的索引，那么这条 SQL 语句就可以利用这个组合索引去进行匹配。当遇到范围查询(\u0026gt;、\u0026lt;、between、like)就会停止匹配，后面的字段不会用到索引。\n对(a,b,c)建立索引，查询条件使用 a/ab/abc 会走索引，使用 bc 不会走索引。\n对(a,b,c,d)建立索引，查询条件为a = 1 and b = 2 and c \u0026gt; 3 and d = 4，那么a、b和c三个字段能用到索引，而d无法使用索引。因为遇到了范围查询。\n如下图，对(a, b) 建立索引，a 在索引树中是全局有序的，而 b 是全局无序，局部有序（当a相等时，会根据b进行排序）。直接执行b = 2这种查询条件无法使用索引。\n当a的值确定的时候，b是有序的。例如a = 1时，b值为1，2是有序的状态。当a = 2时候，b的值为1，4也是有序状态。 当执行a = 1 and b = 2时a和b字段能用到索引。而执行a \u0026gt; 1 and b = 2时，a字段能用到索引，b字段用不到索引。因为a的值此时是一个范围，不是固定的，在这个范围内b值不是有序的，因此b字段无法使用索引。\n什么是聚集索引？ InnoDB使用表的主键构造主键索引树，同时叶子节点中存放的即为整张表的记录数据。聚集索引叶子节点的存储是逻辑上连续的，使用双向链表连接，叶子节点按照主键的顺序排序，因此对于主键的排序查找和范围查找速度比较快。\n聚集索引的叶子节点就是整张表的行记录。InnoDB 主键使用的是聚簇索引。聚集索引要比非聚集索引查询效率高很多。\n对于InnoDB来说，聚集索引一般是表中的主键索引，如果表中没有显示指定主键，则会选择表中的第一个不允许为NULL的唯一索引。如果没有主键也没有合适的唯一索引，那么InnoDB内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键长度为6个字节，它的值会随着数据的插入自增。\n什么是覆盖索引？ select的数据列只用从索引中就能够取得，不需要回表进行二次查询，也就是说查询列要被所使用的索引覆盖。对于innodb表的二级索引，如果索引能覆盖到查询的列，那么就可以避免对主键索引的二次查询。\n不是所有类型的索引都可以成为覆盖索引。覆盖索引要存储索引列的值，而哈希索引、全文索引不存储索引列的值，所以MySQL使用b+树索引做覆盖索引。\n对于使用了覆盖索引的查询，在查询前面使用explain，输出的extra列会显示为using index。\n比如user_like 用户点赞表，组合索引为(user_id, blog_id)，user_id和blog_id都不为null。\nexplain select blog_id from user_like where user_id = 13; explain结果的Extra列为Using index，查询的列被索引覆盖，并且where筛选条件符合最左前缀原则，通过索引查找就能直接找到符合条件的数据，不需要回表查询数据。\nexplain select user_id from user_like where blog_id = 1; explain结果的Extra列为Using where; Using index， 查询的列被索引覆盖，where筛选条件不符合最左前缀原则，无法通过索引查找找到符合条件的数据，但可以通过索引扫描找到符合条件的数据，也不需要回表查询数据。\n索引的设计原则？ 对于经常作为查询条件的字段，应该建立索引，以提高查询速度 为经常需要排序、分组和联合操作的字段建立索引 索引列的区分度越高，索引的效果越好。比如使用性别这种区分度很低的列作为索引，效果就会很差。 避免给\u0026quot;大字段\u0026quot;建立索引。尽量使用数据量小的字段作为索引。因为MySQL在维护索引的时候是会将字段值一起维护的，那这样必然会导致索引占用更多的空间，另外在排序的时候需要花费更多的时间去对比。 尽量使用短索引，对于较长的字符串进行索引时应该指定一个较短的前缀长度，因为较小的索引涉及到的磁盘I/O较少，查询速度更快。 索引不是越多越好，每个索引都需要额外的物理空间，维护也需要花费时间。 频繁增删改的字段不要建立索引。假设某个字段频繁修改，那就意味着需要频繁的重建索引，这必然影响MySQL的性能 利用最左前缀原则。 索引什么时候会失效？ 导致索引失效的情况：\n对于组合索引，不是使用组合索引最左边的字段，则不会使用索引 以%开头的like查询如%abc，无法使用索引；非%开头的like查询如abc%，相当于范围查询，会使用索引 查询条件中列类型是字符串，没有使用引号，可能会因为类型不同发生隐式转换，使索引失效 判断索引列是否不等于某个值时 对索引列进行运算 查询条件使用or连接，也会导致索引失效 什么是前缀索引？ 有时需要在很长的字符列上创建索引，这会造成索引特别大且慢。使用前缀索引可以避免这个问题。\n前缀索引是指对文本或者字符串的前几个字符建立索引，这样索引的长度更短，查询速度更快。\n创建前缀索引的关键在于选择足够长的前缀以保证较高的索引选择性。索引选择性越高查询效率就越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的数据行。\n建立前缀索引的方式：\n// email列创建前缀索引 ALTER TABLE table_name ADD KEY(column_name(prefix_length)); 索引下推 参考我的另一篇文章：图解索引下推！open in new window\n常见的存储引擎有哪些？ MySQL中常用的四种存储引擎分别是： MyISAM、InnoDB、MEMORY、ARCHIVE。MySQL 5.5版本后默认的存储引擎为InnoDB。\nInnoDB存储引擎\nInnoDB是MySQL默认的事务型存储引擎，使用最广泛，基于聚簇索引建立的。InnoDB内部做了很多优化，如能够自动在内存中创建自适应hash索引，以加速读操作。\n优点：支持事务和崩溃修复能力；引入了行级锁和外键约束。\n缺点：占用的数据空间相对较大。\n适用场景：需要事务支持，并且有较高的并发读写频率。\nMyISAM存储引擎\n数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，可以使用MyISAM引擎。MyISAM会将表存储在两个文件中，数据文件.MYD和索引文件.MYI。\n优点：访问速度快。\n缺点：MyISAM不支持事务和行级锁，不支持崩溃后的安全恢复，也不支持外键。\n适用场景：对事务完整性没有要求；表的数据都会只读的。\nMEMORY存储引擎\nMEMORY引擎将数据全部放在内存中，访问速度较快，但是一旦系统奔溃的话，数据都会丢失。\nMEMORY引擎默认使用哈希索引，将键的哈希值和指向数据行的指针保存在哈希索引中。\n优点：访问速度较快。\n缺点：\n哈希索引数据不是按照索引值顺序存储，无法用于排序。 不支持部分索引匹配查找，因为哈希索引是使用索引列的全部内容来计算哈希值的。 只支持等值比较，不支持范围查询。 当出现哈希冲突时，存储引擎需要遍历链表中所有的行指针，逐行进行比较，直到找到符合条件的行。 ARCHIVE存储引擎\nARCHIVE存储引擎非常适合存储大量独立的、作为历史记录的数据。ARCHIVE提供了压缩功能，拥有高效的插入速度，但是这种引擎不支持索引，所以查询性能较差。\nMyISAM和InnoDB的区别？ 存储结构的区别。每个MyISAM在磁盘上存储成三个文件。文件的名字以表的名字开始，扩展名指出文件类型。 .frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。InnoDB所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。 存储空间的区别。MyISAM支持支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。当表在创建之后并导入数据之后，不会再进行修改操作，可以使用压缩表，极大的减少磁盘的空间占用。InnoDB需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。 可移植性、备份及恢复。MyISAM数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。对于InnoDB，可行的方案是拷贝数据文件、备份 binlog，或者用mysqldump，在数据量达到几十G的时候就相对麻烦了。 是否支持行级锁。MyISAM 只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。而InnoDB 支持行级锁和表级锁，默认为行级锁。行锁大幅度提高了多用户并发操作的性能。 是否支持事务和崩溃后的安全恢复。 MyISAM 不提供事务支持。而InnoDB 提供事务支持，具有事务、回滚和崩溃修复能力。 是否支持外键。MyISAM不支持，而InnoDB支持。 是否支持MVCC。MyISAM不支持，InnoDB支持。应对高并发事务，MVCC比单纯的加锁更高效。 是否支持聚集索引。MyISAM不支持聚集索引，InnoDB支持聚集索引。 全文索引。MyISAM支持 FULLTEXT类型的全文索引。InnoDB不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。 表主键。MyISAM允许没有任何索引和主键的表存在，索引都是保存行的地址。对于InnoDB，如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)。 表的行数。MyISAM保存有表的总行数，如果select count(*) from table;会直接取出该值。InnoDB没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了where条件后，MyISAM和InnoDB处理的方式都一样。 MySQL有哪些锁？ 按锁粒度分类，有行级锁、表级锁和页级锁。\n行级锁是mysql中锁定粒度最细的一种锁。表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突，其加锁粒度最小，但加锁的开销也最大。行级锁的类型主要有三类： Record Lock，记录锁，也就是仅仅把一条记录锁上； Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身； Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。 表级锁是mysql中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分mysql引擎支持。最常使用的MyISAM与InnoDB都支持表级锁定。 页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。因此，采取了折衷的页级锁，一次锁定相邻的一组记录。 按锁级别分类，有共享锁、排他锁和意向锁。\n共享锁又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。 排他锁又称写锁、独占锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任何类型的封锁。获准排他锁的事务既能读数据，又能修改数据。 意向锁是表级锁，其设计目的主要是为了在一个事务中揭示下一行将要被请求锁的类型。InnoDB 中的两个表锁： 意向共享锁（IS）：表示事务准备给数据行加入共享锁，也就是说一个数据行加共享锁前必须先取得该表的IS锁；\n意向排他锁（IX）：类似上面，表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的IX锁。\n意向锁是 InnoDB 自动加的，不需要用户干预。\n对于INSERT、UPDATE和DELETE，InnoDB 会自动给涉及的数据加排他锁；对于一般的SELECT语句，InnoDB 不会加任何锁，事务可以通过以下语句显式加共享锁或排他锁。\n共享锁：SELECT … LOCK IN SHARE MODE;\n排他锁：SELECT … FOR UPDATE;\nMVCC 实现原理？ MVCC(Multiversion concurrency control) 就是同一份数据保留多版本的一种方式，进而实现并发控制。在查询的时候，通过read view和版本链找到对应版本的数据。\n作用：提升并发性能。对于高并发场景，MVCC比行级锁开销更小。\nMVCC 实现原理如下：\nMVCC 的实现依赖于版本链，版本链是通过表的三个隐藏字段实现。\nDB_TRX_ID：当前事务id，通过事务id的大小判断事务的时间顺序。 DB_ROLL_PTR：回滚指针，指向当前行记录的上一个版本，通过这个指针将数据的多个版本连接在一起构成undo log版本链。 DB_ROW_ID：主键，如果数据表没有主键，InnoDB会自动生成主键。 每条表记录大概是这样的：\n使用事务更新行记录的时候，就会生成版本链，执行过程如下：\n用排他锁锁住该行； 将该行原本的值拷贝到undo log，作为旧版本用于回滚； 修改当前行的值，生成一个新版本，更新事务id，使回滚指针指向旧版本的记录，这样就形成一条版本链。 下面举个例子方便大家理解。\n1、初始数据如下，其中DB_ROW_ID和DB_ROLL_PTR为空。\n2、事务A对该行数据做了修改，将age修改为12，效果如下：\n3、之后事务B也对该行记录做了修改，将age修改为8，效果如下：\n4、此时undo log有两行记录，并且通过回滚指针连在一起。\n接下来了解下read view的概念。\nread view可以理解成将数据在每个时刻的状态拍成“照片”记录下来。在获取某时刻t的数据时，到t时间点拍的“照片”上取数据。\n在read view内部维护一个活跃事务链表，表示生成read view的时候还在活跃的事务。这个链表包含在创建read view之前还未提交的事务，不包含创建read view之后提交的事务。\n不同隔离级别创建read view的时机不同。\nread committed：每次执行select都会创建新的read_view，保证能读取到其他事务已经提交的修改。 repeatable read：在一个事务范围内，第一次select时更新这个read_view，以后不会再更新，后续所有的select都是复用之前的read_view。这样可以保证事务范围内每次读取的内容都一样，即可重复读。 read view的记录筛选方式\n前提：DATA_TRX_ID 表示每个数据行的最新的事务ID；up_limit_id表示当前快照中的最先开始的事务；low_limit_id表示当前快照中的最慢开始的事务，即最后一个事务。\n如果DATA_TRX_ID \u0026lt; up_limit_id：说明在创建read view时，修改该数据行的事务已提交，该版本的记录可被当前事务读取到。\n如果DATA_TRX_ID \u0026gt;= low_limit_id：说明当前版本的记录的事务是在创建read view之后生成的，该版本的数据行不可以被当前事务访问。此时需要通过版本链找到上一个版本，然后重新判断该版本的记录对当前事务的可见性。\n如果\nup_limit_id \u0026lt;=\nDATA_TRX_ID \u0026lt;\nlow_limit_i ：\n需要在活跃事务链表中查找是否存在ID为DATA_TRX_ID的值的事务。 如果存在，因为在活跃事务链表中的事务是未提交的，所以该记录是不可见的。此时需要通过版本链找到上一个版本，然后重新判断该版本的可见性。 如果不存在，说明事务trx_id 已经提交了，这行记录是可见的。 总结：InnoDB 的MVCC是通过 read view 和版本链实现的，版本链保存有历史版本记录，通过read view 判断当前版本的数据是否可见，如果不可见，再从版本链中找到上一个版本，继续进行判断，直到找到一个可见的版本。\n快照读和当前读 表记录有两种读取方式。\n快照读：读取的是快照版本。普通的SELECT就是快照读。通过mvcc来进行并发控制的，不用加锁。 当前读：读取的是最新版本。UPDATE、DELETE、INSERT、SELECT … LOCK IN SHARE MODE、SELECT … FOR UPDATE是当前读。 快照读情况下，InnoDB通过mvcc机制避免了幻读现象。而mvcc机制无法避免当前读情况下出现的幻读现象。因为当前读每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。\n下面举个例子说明下：\n1、首先，user表只有两条记录，具体如下：\n2、事务a和事务b同时开启事务start transaction；\n3、事务a插入数据然后提交；\ninsert into user(user_name, user_password, user_mail, user_state) values(\u0026#39;tyson\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;, 0); 4、事务b执行全表的update；\nupdate user set user_name = \u0026#39;a\u0026#39;; 5、事务b然后执行查询，查到了事务a中插入的数据。（下图左边是事务b，右边是事务a。事务开始之前只有两条记录，事务a插入一条数据之后，事务b查询出来是三条数据）\n以上就是当前读出现的幻读现象。\n那么MySQL是如何避免幻读？\n在快照读情况下，MySQL通过mvcc来避免幻读。 在当前读情况下，MySQL通过next-key来避免幻读（加行锁和间隙锁来实现的）。 next-key包括两部分：行锁和间隙锁。行锁是加在索引上的锁，间隙锁是加在索引之间的。\nSerializable隔离级别也可以避免幻读，会锁住整张表，并发性极低，一般不会使用。\n共享锁和排他锁 SELECT 的读取锁定主要分为两种方式：共享锁和排他锁。\nselect * from table where id\u0026lt;6 lock in share mode;--共享锁 select * from table where id\u0026lt;6 for update;--排他锁 这两种方式主要的不同在于LOCK IN SHARE MODE 多个事务同时更新同一个表单时很容易造成死锁。\n申请排他锁的前提是，没有线程对该结果集的任何行数据使用排它锁或者共享锁，否则申请会受到阻塞。在进行事务操作时，MySQL会对查询结果集的每行数据添加排它锁，其他线程对这些数据的更改或删除操作会被阻塞（只能读操作），直到该语句的事务被commit语句或rollback语句结束为止。\nSELECT... FOR UPDATE 使用注意事项：\nfor update 仅适用于innodb，且必须在事务范围内才能生效。 根据主键进行查询，查询条件为like或者不等于，主键字段产生表锁。 根据非索引字段进行查询，会产生表锁。 bin log/redo log/undo log MySQL日志主要包括查询日志、慢查询日志、事务日志、错误日志、二进制日志等。其中比较重要的是 bin log（二进制日志）和 redo log（重做日志）和 undo log（回滚日志）。\nbin log\nbin log是MySQL数据库级别的文件，记录对MySQL数据库执行修改的所有操作，不会记录select和show语句，主要用于恢复数据库和同步数据库。\nredo log\nredo log是innodb引擎级别，用来记录innodb存储引擎的事务日志，不管事务是否提交都会记录下来，用于数据恢复。当数据库发生故障，innoDB存储引擎会使用redo log恢复到发生故障前的时刻，以此来保证数据的完整性。将参数innodb_flush_log_at_tx_commit设置为1，那么在执行commit时会将redo log同步写到磁盘。\nundo log\n除了记录redo log外，当进行数据修改时还会记录undo log，undo log用于数据的撤回操作，它保留了记录修改前的内容。通过undo log可以实现事务回滚，并且可以根据undo log回溯到某个特定的版本的数据，实现MVCC。\nbin log和redo log有什么区别？ bin log会记录所有日志记录，包括InnoDB、MyISAM等存储引擎的日志；redo log只记录innoDB自身的事务日志。 bin log只在事务提交前写入到磁盘，一个事务只写一次；而在事务进行过程，会有redo log不断写入磁盘。 bin log是逻辑日志，记录的是SQL语句的原始逻辑；redo log是物理日志，记录的是在某个数据页上做了什么修改。 讲一下MySQL架构？ MySQL主要分为 Server 层和存储引擎层：\nServer 层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。 存储引擎： 主要负责数据的存储和读取。server 层通过api与存储引擎进行通信。 Server 层基本组件\n连接器： 当客户端连接 MySQL 时，server层会对其进行身份认证和权限校验。 查询缓存: 执行查询语句的时候，会先查询缓存，先校验这个 sql 是否执行过，如果有缓存这个 sql，就会直接返回给客户端，如果没有命中，就会执行后续的操作。 分析器: 没有命中缓存的话，SQL 语句就会经过分析器，主要分为两步，词法分析和语法分析，先看 SQL 语句要做什么，再检查 SQL 语句语法是否正确。 优化器： 优化器对查询进行优化，包括重写查询、决定表的读写顺序以及选择合适的索引等，生成执行计划。 执行器： 首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会根据执行计划去调用引擎的接口，返回结果。 分库分表 当单表的数据量达到1000W或100G以后，优化索引、添加从库等可能对数据库性能提升效果不明显，此时就要考虑对其进行切分了。切分的目的就在于减少数据库的负担，缩短查询的时间。\n数据切分可以分为两种方式：垂直划分和水平划分。\n垂直划分\n垂直划分数据库是根据业务进行划分，例如购物场景，可以将库中涉及商品、订单、用户的表分别划分出成一个库，通过降低单库的大小来提高性能。同样的，分表的情况就是将一个大表根据业务功能拆分成一个个子表，例如商品基本信息和商品描述，商品基本信息一般会展示在商品列表，商品描述在商品详情页，可以将商品基本信息和商品描述拆分成两张表。\n优点：行记录变小，数据页可以存放更多记录，在查询时减少I/O次数。\n缺点：\n主键出现冗余，需要管理冗余列； 会引起表连接JOIN操作，可以通过在业务服务器上进行join来减少数据库压力； 依然存在单表数据量过大的问题。 水平划分\n水平划分是根据一定规则，例如时间或id序列值等进行数据的拆分。比如根据年份来拆分不同的数据库。每个数据库结构一致，但是数据得以拆分，从而提升性能。\n优点：单库（表）的数据量得以减少，提高性能；切分出的表结构相同，程序改动较少。\n缺点：\n分片事务一致性难以解决 跨节点join性能差，逻辑复杂 数据分片在扩容时需要迁移 什么是分区表？ 分区是把一张表的数据分成N多个区块。分区表是一个独立的逻辑表，但是底层由多个物理子表组成。\n当查询条件的数据分布在某一个分区的时候，查询引擎只会去某一个分区查询，而不是遍历整个表。在管理层面，如果需要删除某一个分区的数据，只需要删除对应的分区即可。\n分区一般都是放在单机里的，用的比较多的是时间范围分区，方便归档。只不过分库分表需要代码实现，分区则是mysql内部实现。分库分表和分区并不冲突，可以结合使用。\n分区表类型 range分区，按照范围分区。比如按照时间范围分区\nCREATE TABLE test_range_partition( id INT auto_increment, createdate DATETIME, primary key (id,createdate) ) PARTITION BY RANGE (TO_DAYS(createdate) ) ( PARTITION p201801 VALUES LESS THAN ( TO_DAYS(\u0026#39;20180201\u0026#39;) ), PARTITION p201802 VALUES LESS THAN ( TO_DAYS(\u0026#39;20180301\u0026#39;) ), PARTITION p201803 VALUES LESS THAN ( TO_DAYS(\u0026#39;20180401\u0026#39;) ), PARTITION p201804 VALUES LESS THAN ( TO_DAYS(\u0026#39;20180501\u0026#39;) ), PARTITION p201805 VALUES LESS THAN ( TO_DAYS(\u0026#39;20180601\u0026#39;) ), PARTITION p201806 VALUES LESS THAN ( TO_DAYS(\u0026#39;20180701\u0026#39;) ), PARTITION p201807 VALUES LESS THAN ( TO_DAYS(\u0026#39;20180801\u0026#39;) ), PARTITION p201808 VALUES LESS THAN ( TO_DAYS(\u0026#39;20180901\u0026#39;) ), PARTITION p201809 VALUES LESS THAN ( TO_DAYS(\u0026#39;20181001\u0026#39;) ), PARTITION p201810 VALUES LESS THAN ( TO_DAYS(\u0026#39;20181101\u0026#39;) ), PARTITION p201811 VALUES LESS THAN ( TO_DAYS(\u0026#39;20181201\u0026#39;) ), PARTITION p201812 VALUES LESS THAN ( TO_DAYS(\u0026#39;20190101\u0026#39;) ) ); 在/var/lib/mysql/data/可以找到对应的数据文件，每个分区表都有一个使用#分隔命名的表文件：\n-rw-r----- 1 MySQL MySQL 65 Mar 14 21:47 db.opt -rw-r----- 1 MySQL MySQL 8598 Mar 14 21:50 test_range_partition.frm -rw-r----- 1 MySQL MySQL 98304 Mar 14 21:50 test_range_partition#P#p201801.ibd -rw-r----- 1 MySQL MySQL 98304 Mar 14 21:50 test_range_partition#P#p201802.ibd -rw-r----- 1 MySQL MySQL 98304 Mar 14 21:50 test_range_partition#P#p201803.ibd ... list分区\nlist分区和range分区相似，主要区别在于list是枚举值列表的集合，range是连续的区间值的集合。对于list分区，分区字段必须是已知的，如果插入的字段不在分区时的枚举值中，将无法插入。\ncreate table test_list_partiotion ( id int auto_increment, data_type tinyint, primary key(id,data_type) )partition by list(data_type) ( partition p0 values in (0,1,2,3,4,5,6), partition p1 values in (7,8,9,10,11,12), partition p2 values in (13,14,15,16,17) ); hash分区\n可以将数据均匀地分布到预先定义的分区中。\ncreate table test_hash_partiotion ( id int auto_increment, create_date datetime, primary key(id,create_date) )partition by hash(year(create_date)) partitions 10; 分区的问题？ 打开和锁住所有底层表的成本可能很高。当查询访问分区表时，MySQL 需要打开并锁住所有的底层表，这个操作在分区过滤之前发生，所以无法通过分区过滤来降低此开销，会影响到查询速度。可以通过批量操作来降低此类开销，比如批量插入、LOAD DATA INFILE和一次删除多行数据。 维护分区的成本可能很高。例如重组分区，会先创建一个临时分区，然后将数据复制到其中，最后再删除原分区。 所有分区必须使用相同的存储引擎。 查询语句执行流程？ 查询语句的执行流程如下：权限校验、查询缓存、分析器、优化器、权限校验、执行器、引擎。\n举个例子，查询语句如下：\nselect * from user where id \u0026gt; 1 and name = \u0026#39;大彬\u0026#39;; 首先检查权限，没有权限则返回错误； MySQL8.0以前会查询缓存，缓存命中则直接返回，没有则执行下一步； 词法分析和语法分析。提取表名、查询条件，检查语法是否有错误； 两种执行方案，先查 id \u0026gt; 1 还是 name = '大彬'，优化器根据自己的优化算法选择执行效率最好的方案； 校验权限，有权限就调用数据库引擎接口，返回引擎的执行结果。 更新语句执行过程？ 更新语句执行流程如下：分析器、权限校验、执行器、引擎、redo log（prepare状态）、binlog、redo log（commit状态）\n举个例子，更新语句如下：\nupdate user set name = \u0026#39;大彬\u0026#39; where id = 1; 先查询到 id 为1的记录，有缓存会使用缓存。 拿到查询结果，将 name 更新为大彬，然后调用引擎接口，写入更新数据，innodb 引擎将数据保存在内存中，同时记录redo log，此时redo log进入 prepare状态。 执行器收到通知后记录binlog，然后调用引擎接口，提交redo log为commit状态。 更新完成。 为什么记录完redo log，不直接提交，而是先进入prepare状态？\n假设先写redo log直接提交，然后写binlog，写完redo log后，机器挂了，binlog日志没有被写入，那么机器重启后，这台机器会通过redo log恢复数据，但是这个时候binlog并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。\nexist和in的区别？ exists用于对外表记录做筛选。exists会遍历外表，将外查询表的每一行，代入内查询进行判断。当exists里的条件语句能够返回记录行时，条件就为真，返回外表当前记录。反之如果exists里的条件语句不能返回记录行，条件为假，则外表当前记录被丢弃。\nselect a.* from A awhere exists(select 1 from B b where a.id=b.id) in是先把后边的语句查出来放到临时表中，然后遍历临时表，将临时表的每一行，代入外查询去查找。\nselect * from Awhere id in(select id from B) 子查询的表比较大的时候，使用exists可以有效减少总的循环次数来提升速度；当外查询的表比较大的时候，使用in可以有效减少对外查询表循环遍历来提升速度。\nMySQL中int(10)和char(10)的区别？ int(10)中的10表示的是显示数据的长度，而char(10)表示的是存储数据的长度。\ntruncate、delete与drop区别？ 相同点：\ntruncate和不带where子句的delete、以及drop都会删除表内的数据。 drop、truncate都是DDL语句（数据定义语言），执行后会自动提交。 不同点：\ntruncate 和 delete 只删除数据不删除表的结构；drop 语句将删除表的结构被依赖的约束、触发器、索引； 一般来说，执行速度: drop \u0026gt; truncate \u0026gt; delete。 having和where区别？ 二者作用的对象不同，where子句作用于表和视图，having作用于组。 where在数据分组前进行过滤，having在数据分组后进行过滤。 什么是MySQL主从同步？ 主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。\n因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。\n为什么要做主从同步？ 读写分离，使数据库能支撑更大的并发。 在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能。 数据备份，保证数据的安全。 乐观锁和悲观锁是什么？ 数据库中的并发控制是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观锁和悲观锁是并发控制主要采用的技术手段。\n悲观锁：假定会发生并发冲突，会对操作的数据进行加锁，直到提交事务，才会释放锁，其他事务才能进行修改。实现方式：使用数据库中的锁机制。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否数据是否被修改过。给表增加version字段，在修改提交之前检查version与原来取到的version值是否相等，若相等，表示数据没有被修改，可以更新，否则，数据为脏数据，不能更新。实现方式：乐观锁一般使用版本号机制或CAS算法实现。 用过processlist吗？ show processlist 或 show full processlist 可以查看当前 MySQL 是否有压力，正在运行的SQL，有没有慢SQL正在执行。返回参数如下：\nid：线程ID，可以用kill id杀死某个线程\ndb：数据库名称\nuser：数据库用户\nhost：数据库实例的IP\ncommand：当前执行的命令，比如Sleep，Query，Connect 等\ntime：消耗时间，单位秒\nstate\n：执行状态，主要有以下状态：\nSleep，线程正在等待客户端发送新的请求 Locked，线程正在等待锁 Sending data，正在处理SELECT查询的记录，同时把结果发送给客户端 Kill，正在执行kill语句，杀死指定线程 Connect，一个从节点连上了主节点 Quit，线程正在退出 Sorting for group，正在为GROUP BY做排序 Sorting for order，正在为ORDER BY做排序 info：正在执行的SQL语句\nMySQL查询 limit 1000,10 和limit 10 速度一样快吗？ 两种查询方式。对应 limit offset, size 和 limit size 两种方式。\n而其实 limit size ，相当于 limit 0, size。也就是从0开始取size条数据。\n也就是说，两种方式的区别在于offset是否为0。\n先来看下limit sql的内部执行逻辑。\nMySQL内部分为server层和存储引擎层。一般情况下存储引擎都用innodb。\nserver层有很多模块，其中需要关注的是执行器是用于跟存储引擎打交道的组件。\n执行器可以通过调用存储引擎提供的接口，将一行行数据取出，当这些数据完全符合要求（比如满足其他where条件），则会放到结果集中，最后返回给调用mysql的客户端。\n以主键索引的limit执行过程为例：\n执行select * from xxx order by id limit 0, 10;，select后面带的是星号，也就是要求获得行数据的所有字段信息。\nserver层会调用innodb的接口，在innodb里的主键索引中获取到第0到10条完整行数据，依次返回给server层，并放到server层的结果集中，返回给客户端。\n把offset搞大点，比如执行的是：select * from xxx order by id limit 500000, 10;\nserver层会调用innodb的接口，由于这次的offset=500000，会在innodb里的主键索引中获取到第0到（500000 + 10）条完整行数据，返回给server层之后根据offset的值挨个抛弃，最后只留下最后面的size条，也就是10条数据，放到server层的结果集中，返回给客户端。\n可以看出，当offset非0时，server层会从引擎层获取到很多无用的数据，而获取的这些无用数据都是要耗时的。\n因此，mysql查询中 limit 1000,10 会比 limit 10 更慢。原因是 limit 1000,10 会取出1000+10条数据，并抛弃前1000条，这部分耗时更大。\n深分页怎么优化？ 还是以上面的SQL为空：select * from xxx order by id limit 500000, 10;\n方法一：\n从上面的分析可以看出，当offset非常大时，server层会从引擎层获取到很多无用的数据，而当select后面是*号时，就需要拷贝完整的行信息，拷贝完整数据相比只拷贝行数据里的其中一两个列字段更耗费时间。\n因为前面的offset条数据最后都是不要的，没有必要拷贝完整字段，所以可以将sql语句修改成：\nselect * from xxx where id \u0026gt;=(select id from xxx order by id limit 500000, 1) order by id limit 10; 先执行子查询 select id from xxx by id limit 500000, 1, 这个操作，其实也是将在innodb中的主键索引中获取到500000+1条数据，然后server层会抛弃前500000条，只保留最后一条数据的id。\n但不同的地方在于，在返回server层的过程中，只会拷贝数据行内的id这一列，而不会拷贝数据行的所有列，当数据量较大时，这部分的耗时还是比较明显的。\n在拿到了上面的id之后，假设这个id正好等于500000，那sql就变成了\nselect * from xxx where id \u0026gt;=500000 order by id limit 10; 这样innodb再走一次主键索引，通过B+树快速定位到id=500000的行数据，时间复杂度是lg(n)，然后向后取10条数据。\n方法二：\n将所有的数据根据id主键进行排序，然后分批次取，将当前批次的最大id作为下次筛选的条件进行查询。\nselect * from xxx where id \u0026gt; start_id order by id limit 10; 通过主键索引，每次定位到start_id的位置，然后往后遍历10个数据，这样不管数据多大，查询性能都较为稳定。\n高度为3的B+树，可以存放多少数据？ InnoDB存储引擎有自己的最小储存单元——页（Page）。\n查询InnoDB页大小的命令如下：\nmysql\u0026gt; show global status like \u0026#39;innodb_page_size\u0026#39;; +------------------+-------+ | Variable_name | Value | +------------------+-------+ | Innodb_page_size | 16384 | +------------------+-------+ 可以看出 innodb 默认的一页大小为 16384B = 16384/1024 = 16kb。\n在MySQL中，B+树一个节点的大小设为一页或页的倍数最为合适。因为如果一个节点的大小 \u0026lt; 1页，那么读取这个节点的时候其实读取的还是一页，这样就造成了资源的浪费。\nB+树中非叶子节点存的是key + 指针；叶子节点存的是数据行。\n对于叶子节点，如果一行数据大小为1k，那么一页就能存16条数据。\n对于非叶子节点，如果key使用的是bigint，则为8字节，指针在MySQL中为6字节，一共是14字节，则16k能存放 16 * 1024 / 14 = 1170 个索引指针。\n于是可以算出，对于一颗高度为2的B+树，根节点存储索引指针节点，那么它有1170个叶子节点存储数据，每个叶子节点可以存储16条数据，一共 1170 x 16 = 18720 条数据。而对于高度为3的B+树，就可以存放 1170 x 1170 x 16 = 21902400 条数据（两千多万条数据），也就是对于两千多万条的数据，我们只需要高度为3的B+树就可以完成，通过主键查询只需要3次IO操作就能查到对应数据。\n所以在 InnoDB 中B+树高度一般为3层时，就能满足千万级的数据存储。\n参考：https://www.cnblogs.com/leefreeman/p/8315844.htmlopen in new window\nMySQL单表多大进行分库分表？ 目前主流的有两种说法：\nMySQL 单表数据量大于 2000 万行，性能会明显下降，考虑进行分库分表。 阿里巴巴《Java 开发手册》提出单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。 事实上，这个数值和实际记录的条数无关，而与 MySQL 的配置以及机器的硬件有关。因为MySQL为了提高性能，会将表的索引装载到内存中。在InnoDB buffer size 足够的情况下，其能完成全加载进内存，查询不会有问题。但是，当单表数据库到达某个量级的上限时，导致内存无法存储其索引，使得之后的 SQL 查询会产生磁盘 IO，从而导致性能下降。当然，这个还有具体的表结构的设计有关，最终导致的问题都是内存限制。\n因此，对于分库分表，需要结合实际需求，不宜过度设计，在项目一开始不采用分库与分表设计，而是随着业务的增长，在无法继续优化的情况下，再考虑分库与分表提高系统的性能。对此，阿里巴巴《Java 开发手册》补充到：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。\n至于MySQL单表多大进行分库分表，应当根据机器资源进行评估。\n大表查询慢怎么优化？ 某个表有近千万数据，查询比较慢，如何优化？\n当MySQL单表记录数过大时，数据库的性能会明显下降，一些常见的优化措施如下：\n合理建立索引。在合适的字段上建立索引，例如在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描 索引优化，SQL优化。索引要符合最左匹配原则等，参考：https://topjavaer.cn/database/mysql.html#什么是覆盖索引open in new window 建立分区。对关键字段建立水平分区，比如时间字段，若查询条件往往通过时间范围来进行查询，能提升不少性能 利用缓存。利用Redis等缓存热点数据，提高查询效率 限定数据的范围。比如：用户在查询历史信息的时候，可以控制在一个月的时间范围内 读写分离。经典的数据库拆分方案，主库负责写，从库负责读 通过分库分表的方式进行优化，主要有垂直拆分和水平拆分 数据异构到es 冷热数据分离。几个月之前不常用的数据放到冷库中，最新的数据比较新的数据放到热库中 升级数据库类型，换一种能兼容MySQL的数据库（OceanBase、TiDB等） 说说count(1)、count(*)和count(字段名)的区别 嗯，先说说count(1) and count(字段名)的区别。\n两者的主要区别是\ncount(1) 会统计表中的所有的记录数，包含字段为null 的记录。 count(字段名) 会统计该字段在表中出现的次数，忽略字段为null 的情况。即不统计字段为null 的记录。 接下来看看三者之间的区别。\n执行效果上：\ncount(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL count(1)包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL count(字段名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。 执行效率上：\n列名为主键，count(字段名)会比count(1)快 列名不为主键，count(1)会比count(列名)快 如果表多个列并且没有主键，则 count(1) 的执行效率优于 count(*) 如果有主键，则 select count(主键)的执行效率是最优的 如果表只有一个字段，则 select count(*)最优。 MySQL中DATETIME 和 TIMESTAMP有什么区别？ 嗯，TIMESTAMP和DATETIME都可以用来存储时间，它们主要有以下区别：\n1.表示范围\nDATETIME：1000-01-01 00:00:00.000000 到 9999-12-31 23:59:59.999999 TIMESTAMP：\u0026lsquo;1970-01-01 00:00:01.000000\u0026rsquo; UTC 到 \u0026lsquo;2038-01-09 03:14:07.999999\u0026rsquo; UTC TIMESTAMP支持的时间范围比DATATIME要小，容易出现超出的情况。\n2.空间占用\nTIMESTAMP ：占 4 个字节 DATETIME：在 MySQL 5.6.4 之前，占 8 个字节 ，之后版本，占 5 个字节 3.存入时间是否会自动转换\nTIMESTAMP类型在默认情况下，insert、update 数据时，TIMESTAMP列会自动以当前时间（CURRENT_TIMESTAMP）填充/更新。DATETIME则不会做任何转换，也不会检测时区，你给什么数据，它存什么数据。\n4.TIMESTAMP比较受时区timezone的影响以及MYSQL版本和服务器的SQL MODE的影响。因为TIMESTAMP存的是时间戳，在不同的时区得出的时间不一致。\n5.如果存进NULL，两者实际存储的值不同。\nTIMESTAMP：会自动存储当前时间 now() 。 DATETIME：不会自动存储当前时间，会直接存入 NULL 值。 说说为什么不建议用外键？ 外键是一种约束，这个约束的存在，会保证表间数据的关系始终完整。外键的存在，并非全然没有优点。\n外键可以保证数据的完整性和一致性，级联操作方便。而且使用外键可以将数据完整性判断托付给了数据库完成，减少了程序的代码量。\n虽然外键能够保证数据的完整性，但是会给系统带来很多缺陷。\n1、并发问题。在使用外键的情况下，每次修改数据都需要去另外一个表检查数据，需要获取额外的锁。若是在高并发大流量事务场景，使用外键更容易造成死锁。\n2、扩展性问题。比如从MySQL迁移到Oracle，外键依赖于数据库本身的特性，做迁移可能不方便。\n3、不利于分库分表。在水平拆分和分库的情况下，外键是无法生效的。将数据间关系的维护，放入应用程序中，为将来的分库分表省去很多的麻烦。\n使用自增主键有什么好处？ 自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑，在查询的时候，效率也就更高。\n自增主键保存在什么地方？ 不同的引擎对于自增值的保存策略不同：\nMyISAM引擎的自增值保存在数据文件中。 在MySQL8.0以前，InnoDB引擎的自增值是存在内存中。MySQL重启之后内存中的这个值就丢失了，每次重启后第一次打开表的时候，会找自增值的最大值max(id)，然后将最大值加1作为这个表的自增值；MySQL8.0版本会将自增值的变更记录在redo log中，重启时依靠redo log恢复。 自增主键一定是连续的吗？ 不一定，有几种情况会导致自增主键不连续。\n1、唯一键冲突导致自增主键不连续。当我们向一个自增主键的InnoDB表中插入数据的时候，如果违反表中定义的唯一索引的唯一约束，会导致插入数据失败。此时表的自增主键的键值是会向后加1滚动的。下次再次插入数据的时候，就不能再使用上次因插入数据失败而滚动生成的键值了，必须使用新滚动生成的键值。\n2、事务回滚导致自增主键不连续。当我们向一个自增主键的InnoDB表中插入数据的时候，如果显式开启了事务，然后因为某种原因最后回滚了事务，此时表的自增值也会发生滚动，而接下里新插入的数据，也将不能使用滚动过的自增值，而是需要重新申请一个新的自增值。\n3、批量插入导致自增值不连续。MySQL有一个批量申请自增id的策略：\n语句执行过程中，第一次申请自增id，分配1个自增id 1个用完以后，第二次申请，会分配2个自增id 2个用完以后，第三次申请，会分配4个自增id 依次类推，每次申请都是上一次的两倍（最后一次申请不一定全部使用） 如果下一个事务再次插入数据的时候，则会基于上一个事务申请后的自增值基础上再申请。此时就出现自增值不连续的情况出现。\n4、自增步长不是1，也会导致自增主键不连续。\nInnoDB的自增值为什么不能回收利用？ 主要为了提升插入数据的效率和并行度。\n假设有两个并行执行的事务，在申请自增值的时候，为了避免两个事务申请到相同的自增 id，肯定要加锁，然后顺序申请。\n假设事务 A 申请到了 id=2， 事务 B 申请到 id=3，那么这时候表 t 的自增值是 4，之后继续执行。\n事务 B 正确提交了，但事务 A 出现了唯一键冲突。\n如果允许事务 A 把自增 id 回退，也就是把表 t 的当前自增值改回 2，那么就会出现这样的情况：表里面已经有 id=3 的行，而当前的自增 id 值是 2。\n接下来，继续执行的其他事务就会申请到 id=2，然后再申请到 id=3。这时，就会出现插入语句报错“主键冲突”。\n而为了解决这个主键冲突，有两种方法：\n每次申请 id 之前，先判断表里面是否已经存在这个 id。如果存在，就跳过这个 id。但是，这个方法的成本很高。因为，本来申请 id 是一个很快的操作，现在还要再去主键索引树上判断 id 是否存在。 把自增 id 的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增 id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降。 可见，这两个方法都会导致性能问题。\n因此，InnoDB 放弃了“允许自增 id 回退”这个设计，语句执行失败也不回退自增 id。\nMySQL数据如何同步到Redis缓存？ 参考：https://cloud.tencent.com/developer/article/1805755open in new window\n有两种方案：\n1、通过MySQL自动同步刷新Redis，MySQL触发器+UDF函数实现。\n过程大致如下：\n在MySQL中对要操作的数据设置触发器Trigger，监听操作 客户端向MySQL中写入数据时，触发器会被触发，触发之后调用MySQL的UDF函数 UDF函数可以把数据写入到Redis中，从而达到同步的效果 2、解析MySQL的binlog，实现将数据库中的数据同步到Redis。可以通过canal实现。canal是阿里巴巴旗下的一款开源项目，基于数据库增量日志解析，提供增量数据订阅\u0026amp;消费。\ncanal的原理如下：\ncanal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议 mysql master收到dump请求，开始推送binary log给canal canal解析binary log对象（原始为byte流），将数据同步写入Redis。 为什么阿里Java手册禁止使用存储过程？ 先看看什么是存储过程。\n存储过程是在大型数据库系统中，一组为了完成特定功能的SQL 语句集，它存储在数据库中，一次编译后永久有效，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。\n存储过程主要有以下几个缺点。\n存储过程难以调试。存储过程的开发一直缺少有效的 IDE 环境。SQL 本身经常很长，调试式要把句子拆开分别独立执行，非常麻烦。 移植性差。存储过程的移植困难，一般业务系统总会不可避免地用到数据库独有的特性和语法，更换数据库时这部分代码就需要重写，成本较高。 管理困难。存储过程的目录是扁平的，而不是文件系统那样的树形结构，脚本少的时候还好办，一旦多起来，目录就会陷入混乱。 存储过程是只优化一次，有的时候随着数据量的增加或者数据结构的变化，原来存储过程选择的执行计划也许并不是最优的了，所以这个时候需要手动干预或者重新编译了。 MySQL update 是锁行还是锁表？ 首先，InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。\n当执行update语句时，where中的过滤条件列，如果用到索引，就是锁行；如果无法用索引，就是锁表。 如果两个update语句同时执行，第一个先执行触发行锁，但是第二个没有索引触发表锁，因为有个行锁住了，所以还是会等待行锁释放，才能锁表。 当执行insert或者delete语句时，锁行。 select\u0026hellip;for update会锁表还是锁行？ 如果查询条件用了索引/主键，那么select ... for update就会加行锁。\n如果是普通字段(没有索引/主键)，那么select ..... for update就会加表锁。\nMySQL的binlog有几种格式？分别有什么区别？ 有三种格式，statement，row和mixed。\nstatement：每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。 row：不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。 mixed：一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。 阿里手册为什么禁止使用 count(列名)或 count(常量)来替代 count(*) 先看下这几种方式的区别。\ncount(主键id)：InnoDB引擎会遍历整张表，把每一行id值都取出来，返给server层。server层拿到id后，判断是不可能为空的，就按行累加，不再对每个值进行NULL判断。\ncount(常量)：InnoDB引擎会遍历整张表，但不取值。server层对于返回的每一行，放一个常量进去，判断是不可能为空的，按行累加，不再对每个值进行NULL判断。count(常量)比count(主键id)执行的要快，因为从引擎放回id会涉及解析数据行，以及拷贝字段值的操作。\ncount(字段)：全表扫描，分情况讨论。\n1、如果参数字段定义NOT NULL，判断是不可能为空的，按行累加，不再对每个值进行NULL判断。 2、如果参数字段定义允许为NULL，那么执行的时候，判断可能是NULL，还要把值取出来再判断一下，不是NULL才累加。\ncount(*)：统计所有的列，相当于行数，统计结果中会包含字段值为null的列；\nCOUNT(*)是SQL92定义的标准统计行数的语法，效率高，MySQL对它进行了很多优化，MyISAM中会直接把表的总行数单独记录下来供COUNT(*)查询，而InnoDB则会在扫表的时候选择最小的索引来降低成本。\n所以，建议使用COUNT(*)查询表的行数！\n存储MD5值应该用VARCHAR还是用CHAR？ 首先说说CHAR和VARCHAR的区别：\n1、存储长度：\nCHAR类型的长度是固定的\n当我们当定义CHAR(10)，输入的值是\u0026quot;abc\u0026rdquo;，但是它占用的空间一样是10个字节，会包含7个空字节。当输入的字符长度超过指定的数时，CHAR会截取超出的字符。而且，当存储为CHAR的时候，MySQL会自动删除输入字符串末尾的空格。\nVARCHAR的长度是可变的\n比如VARCHAR(10)，然后输入abc三个字符，那么实际存储大小为3个字节。\n除此之外，VARCHAR还会保留1个或2个额外的字节来记录字符串的实际长度。如果定义的最大长度小于等于255个字节，那么，就会预留1个字节；如果定义的最大长度大于255个字节，那么就会预留2个字节。\n2、存储效率\nCHAR类型每次修改后的数据长度不变，效率更高。\nVARCHAR每次修改的数据要更新数据长度，效率更低。\n3、存储空间\nCHAR存储空间是初始的预计长度字符串再加上一个记录字符串长度的字节，可能会存在多余的空间。\nVARCHAR存储空间的时候是实际字符串再加上一个记录字符串长度的字节，占用空间较小。\n根据以上的分析，由于MD5是一个定长的值，所以MD5值适合使用CHAR存储。对于固定长度的非常短的列，CHAR比VARCHAR效率也更高。\n","permalink":"https://yurooc.github.io/blog/mysql%E9%9D%A2%E7%BB%8F/","summary":"什么是MySQL MySQL是一个关系型数据库，它采用表的形式来存储数据。你可以理解成是Excel表格，既然是表的形式存储数据，就有表结构（行","title":"Mysql面经"},{"content":"Python基础 1.python新式类和经典类的区别？ a. 在python里凡是继承了object的类，都是新式类\nb. Python3里只有新式类\nc. Python2里面继承object的是新式类，没有写父类的是经典类\nd. 经典类目前在Python里基本没有应用\ne. 保持class与type的统一对新式类的实例执行a.__class__与type(a)的结果是一致的，对于旧式类来说就不一样了。\nf. 对于多重继承的属性搜索顺序不一样新式类是采用广度优先搜索，旧式类采用深度优先搜索。\n2.python中内置的数据结构有几种？ a. 整型 int、 长整型 long、浮点型 float、 复数 complex\nb. 字符串 str、 列表 list、 元组 tuple\nc. 字典 dict 、 集合 set\nd. Python3 中没有 long，只有无限精度的 int\n3.python如何实现单例模式?请写出两种实现方式? 第一种方法:使用装饰器\ndef singleton(cls): instances = {} def wrapper(*args, **kwargs): if cls not in instances: instances[cls] = cls(*args, **kwargs) return instances[cls] return wrapper @singleton class Foo(object): pass foo1 = Foo() foo2 = Foo() print(foo1 is foo2) # True 第二种方法：使用基类 New 是真正创建实例对象的方法，所以重写基类的new 方法，以此保证创建对象的时候只生成一个实例\nclass Singleton(object): def __new__(cls, *args, **kwargs): if not hasattr(cls, \u0026#39;_instance\u0026#39;): cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls._instance class Foo(Singleton): pass foo1 = Foo() foo2 = Foo() print(foo1 is foo2) # True 第三种方法：元类，元类是用于创建类对象的类，类对象创建实例对象时一定要调用call方法，因此在调用call时候保证始终只创建一个实例即可，type是python的元类\nclass Singleton(type): def __call__(cls, *args, **kwargs): if not hasattr(cls, \u0026#39;_instance\u0026#39;): cls._instance = super(Singleton, cls).__call__(*args, **kwargs) return cls._instance # Python2 class Foo(object): __metaclass__ = Singleton # Python3 class Foo(metaclass=Singleton): pass foo1 = Foo() foo2 = Foo() print(foo1 is foo2) # True 4.可变类型和不可变类型 1,可变类型有list,dict.不可变类型有string,number,tuple.\n2,当进行修改操作时，可变类型传递的是内存中的地址，也就是说，直接修改内存中的值，并没有开辟新的内存。\n3,不可变类型被改变时，并没有改变原内存地址中的值，而是开辟一块新的内存，将原地址中的值复制过去，对这块新开辟的内存中的值进行操作。\n5.is和==有什么区别？ is：比较的是两个对象的id值是否相等，也就是比较俩对象是否为同一个实例对象。是否指向同一个内存地址\n== ： 比较的两个对象的内容/值是否相等，默认会调用对象的eq()方法\n6.Python中变量的作用域？（变量查找顺序) 函数作用域的LEGB顺序\n1.什么是LEGB?\nL: local 函数内部作用域\nE: enclosing 函数内部与内嵌函数之间\nG: global 全局作用域\nB: build-in 内置作用\npython在函数里面的查找分为4种，称之为LEGB，也正是按照这是顺序来查找的\n7.super函数的具体用法和场景 https://python3-cookbook.readthedocs.io/zh_CN/latest/c08/p07_calling_method_on_parent_class.html\nPython高级 元类 1.Python中类方法、类实例方法、静态方法有何区别？ 类方法: 是类对象的方法，在定义时需要在上方使用 @classmethod 进行装饰,形参为cls，表示类对象，类对象和实例对象都可调用\n类实例方法: 是类实例化对象的方法,只有实例对象可以调用，形参为self,指代对象本身;\n静态方法: 是一个任意函数，在其上方使用 @staticmethod 进行装饰，可以用对象直接调用，静态方法实际上跟该类没有太大关系\n2.介绍Cython，Pypy Cpython Numba各有什么缺点 Cython\n3.请描述抽象类和接口类的区别和联系 1.抽象类： 规定了一系列的方法，并规定了必须由继承类实现的方法。由于有抽象方法的存在，所以抽象类不能实例化。可以将抽象类理解为毛坯房，门窗，墙面的样式由你自己来定，所以抽象类与作为基类的普通类的区别在于约束性更强\n2.接口类：与抽象类很相似，表现在接口中定义的方法，必须由引用类实现，但他与抽象类的根本区别在于用途：与不同个体间沟通的规则，你要进宿舍需要有钥匙，这个钥匙就是你与宿舍的接口，你的舍友也有这个接口，所以他也能进入宿舍，你用手机通话，那么手机就是你与他人交流的接口\n3.区别和关联：\n1.接口是抽象类的变体，接口中所有的方法都是抽象的，而抽象类中可以有非抽象方法，抽象类是声明方法的存在而不去实现它的类\n2.接口可以继承，抽象类不行\n3.接口定义方法，没有实现的代码，而抽象类可以实现部分方法\n4.接口中基本数据类型为static而抽象类不是\n什么是Python中的GIL？ 全局解释器锁 GIL，对于每一个进程都具有一个 GIL ，它的直接作用是限制单个进程中多线程的并行执行，使得即使在多核处理器上对于单个进程来说，在同一时刻运行的线程仅限一个。\nPython的多线程是伪多线程，无法利用多核资源，同一个时刻只有一个线程在真正的运行。\n内存管理与垃圾回收机制 1.哪些操作会导致Python内存溢出，怎么处理？ 2.关于Python内存管理,下列说法错误的是 B A,变量不必事先声明 B,变量无须先创建和赋值而直接使用\nC,变量无须指定类型 D,可以使用del释放资源\n3.Python的内存管理机制及调优手段？ 内存管理机制: 引用计数、垃圾回收、内存池\n引用计数：引用计数是一种非常高效的内存管理手段，当一个Python对象被引用时其引用计数增加1,\n当其不再被一个变量引用时则计数减1,当引用计数等于0时对象被删除。弱引用不会增加引用计数\n垃圾回收：\n1.引用计数\n引用计数也是一种垃圾收集机制，而且也是一种最直观、最简单的垃圾收集技术。当Python的某个对象的引用计数降为0时，说明没有任何引用指向该对象，该对象就成为要被回收的垃圾了。比如某个新建对象，它被分配给某个引用，对象的引用计数变为1，如果引用被删除，对象的引用计数为0,那么该对象就可以被垃圾回收。不过如果出现循环引用的话，引用计数机制就不再起有效的作用了。\n2.标记清除\n标记清除主要是解决循环引用问题。\n标记清除算法是一种基于追踪回收（tracing GC）技术实现的垃圾回收算法。\n它分为两个阶段：第一阶段是标记阶段，GC 会把所有的 活动对象 打上标记，第二阶段是把那些没有标记的对象 非活动对象 进行回收。那么 GC 又是如何判断哪些是活动对象哪些是非活动对象的呢？\n对象之间通过引用（指针）连在一起，构成一个有向图，对象构成这个有向图的节点，而引用关系构成这个有向图的边。从根对象（root object）出发，沿着有向边遍历对象，可达的（reachable）对象标记为活动对象，不可达的对象就是要被清除的非活动对象。根对象就是全局变量、调用栈、寄存器。\n3.分代技术\n分代回收是一种以空间换时间的操作方式。\nPython 将内存根据对象的存活时间划分为不同的集合，每个集合称为一个代，Python 将内存分为了 3“代”，分别为年轻代（第 0 代）、中年代（第 1 代）、老年代（第 2 代），他们对应的是 3 个链表，它们的垃圾收集频率与对象的存活时间的增大而减小。新创建的对象都会分配在年轻代，年轻代链表的总数达到上限时，Python 垃圾收集机制就会被触发，把那些可以被回收的对象回收掉，而那些不会回收的对象就会被移到中年代去，依此类推，老年代中的对象是存活时间最久的对象，甚至是存活于整个系统的生命周期内。同时，分代回收是建立在标记清除技术基础之上。\n调优手段\n1.手动垃圾回收\n2.调高垃圾回收阈值\n3.避免循环引用\n4.内存泄露是什么？如何避免？ 内存泄漏指由于疏忽或错误造成程序未能释放已经不再使用的内存。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，导致在释放该段内存之前就失去了对该段内存的控制，从而造成了内存的浪费。\n有__del__()函数的对象间的循环引用是导致内存泄露的主凶。不使用一个对象时使用: del object 来删除一个对象的引用计数就可以有效防止内存泄露问题。\n通过Python扩展模块gc 来查看不能回收的对象的详细信息。\n可以通过 sys.getrefcount(obj) 来获取对象的引用计数，并根据返回值是否为0来判断是否内存泄露\n函数 1.简述read、readline、readlines的区别？ read 读取整个文件\nreadline 读取下一行\nreadlines 读取整个文件到一个迭代器以供我们遍历\n2.什么是Hash（散列函数）？ 散列函数（英语：Hash function）又称散列算法、哈希函数，是一种从任何一种数据中创建小的数字“指纹”的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。该函数将数据打乱混合，重新创建一个叫做散列值（hash values，hash codes，hash sums，或hashes）的指纹。散列值通常用一个短的随机字母和数字组成的字符串来代表\n3.python函数重载机制？ 函数重载主要是为了解决两个问题。 1。可变参数类型。 2。可变参数个数。\n另外，一个基本的设计原则是，仅仅当两个函数除了参数类型和参数个数不同以外，其功能是完全相同的，此时才使用函数重载，如果两个函数的功能其实不同，那么不应当使用重载，而应当使用一个名字不同的函数。\n好吧，那么对于情况 1 ，函数功能相同，但是参数类型不同，python 如何处理？答案是根本不需要处理，因为 python 可以接受任何类型的参数，如果函数的功能相同，那么不同的参数类型在 python 中很可能是相同的代码，没有必要做成两个不同函数。\n那么对于情况 2 ，函数功能相同，但参数个数不同，python 如何处理？大家知道，答案就是缺省参数。对那些缺少的参数设定为缺省参数即可解决问题。因为你假设函数功能相同，那么那些缺少的参数终归是需要用的。\n好了，鉴于情况 1 跟 情况 2 都有了解决方案，python 自然就不需要函数重载了。\n4.函数调用参数的传递方式是值传递还是引用传递？ Python的参数传递有：位置参数、默认参数、可变参数、关键字参数。\n函数的传值到底是值传递还是引用传递、要分情况：\n不可变参数用值传递：像整数和字符串这样的不可变对象，是通过拷贝进行传递的，因为你无论如何都不可能在原处改变不可变对象。\n可变参数是引用传递：比如像列表，字典这样的对象是通过引用传递、和C语言里面的用指针传递数组很相似，可变对象能在函数内部改变。\n5.如何在function里面设置一个全局变量 globals() # 返回包含当前作用余全局变量的字典。 global 变量 设置使用全局变量 6.对缺省参数的理解 ？ 缺省参数指在调用函数的时候没有传入参数的情况下，调用默认的参数，在调用函数的同时赋值时，所传入的参数会替代默认参数。\n*args是不定长参数，它可以表示输入参数是不确定的，可以是任意多个。\n**kwargs是关键字参数，赋值的时候是以键值对的方式，参数可以是任意多对在定义函数的时候\n不确定会有多少参数会传入时，就可以使用两个参数\n7.Mysql怎么限制IP访问？ 8.带参数的装饰器? 带定长参数的装饰器\ndef new_func(func): def wrappedfun(username, passwd): if username == \u0026#39;root\u0026#39; and passwd == \u0026#39;123456789\u0026#39;: print(\u0026#39;通过认证\u0026#39;) print(\u0026#39;开始执行附加功能\u0026#39;) return func() else: print(\u0026#39;用户名或密码错误\u0026#39;) return return wrappedfun @new_func def origin(): print(\u0026#39;开始执行函数\u0026#39;) origin(\u0026#39;root\u0026#39;,\u0026#39;123456789\u0026#39;) 带不定长参数的装饰器\ndef new_func(func): def wrappedfun(*parts): if parts: counts = len(parts) print(\u0026#39;本系统包含 \u0026#39;, end=\u0026#39;\u0026#39;) for part in parts: print(part, \u0026#39; \u0026#39;,end=\u0026#39;\u0026#39;) print(\u0026#39;等\u0026#39;, counts, \u0026#39;部分\u0026#39;) return func() else: print(\u0026#39;用户名或密码错误\u0026#39;) return func() return wrappedfun 9.为什么函数名字可以当做参数用? Python中一切皆对象，函数名是函数在内存中的空间，也是一个对象\n10.map函数和reduce函数？ map(lambda x: x * x, [1, 2, 3, 4]) # 使用 lambda # [1, 4, 9, 16] reduce(lambda x, y: x * y, [1, 2, 3, 4]) # 相当于 ((1 * 2) * 3) * 4 # 24 11.回调函数，如何通信的? 回调函数是把函数的指针(地址)作为参数传递给另一个函数，将整个函数当作一个对象，赋值给调用的函数。\n12.Python主要的内置数据类型都有哪些？ print dir( ‘a ’) 的输出？ 内建类型：布尔类型，数字，字符串，列表，元组，字典，集合\n输出字符串\u0026rsquo;a\u0026rsquo;的内建方法\n13.hasattr() getattr() setattr() 函数使用详解？ hasattr(object,name)函数:\n判断一个对象里面是否有name属性或者name方法，返回bool值，有name属性（方法）返回True，否则返回False。\nclass function_demo(object): name = \u0026#39;demo\u0026#39; def run(self): return \u0026#34;hello function\u0026#34; functiondemo = function_demo() res = hasattr(functiondemo, \u0026#34;name\u0026#34;) # 判断对象是否有name属性，True res = hasattr(functiondemo, \u0026#34;run\u0026#34;) # 判断对象是否有run方法，True res = hasattr(functiondemo, \u0026#34;age\u0026#34;) # 判断对象是否有age属性，False print(res) getattr(object, name[,default])函数：\n获取对象object的属性或者方法，如果存在则打印出来，如果不存在，打印默认值，默认值可选。注意：如果返回的是对象的方法，则打印结果是：方法的内存地址，如果需要运行这个方法，可以在后面添加括号().\nfunctiondemo = function_demo() getattr(functiondemo, \u0026#34;name\u0026#34;)# 获取name属性，存在就打印出来 --- demo getattr(functiondemo, \u0026#34;run\u0026#34;) # 获取run 方法，存在打印出方法的内存地址 getattr(functiondemo, \u0026#34;age\u0026#34;) # 获取不存在的属性，报错 getattr(functiondemo, \u0026#34;age\u0026#34;, 18)# 获取不存在的属性，返回一个默认值 setattr(object, name, values)函数：\n给对象的属性赋值，若属性不存在，先创建再赋值\nclass function_demo(object): name = \u0026#34;demo\u0026#34; def run(self): return \u0026#34;hello function\u0026#34; functiondemo = function_demo() res = hasattr(functiondemo, \u0026#34;age\u0026#34;) # 判断age属性是否存在，False print(res) setattr(functiondemo, \u0026#34;age\u0026#34;, 18) # 对age属性进行赋值，无返回值 res1 = hasattr(functiondemo, \u0026#34;age\u0026#34;) # 再次判断属性是否存在，True 综合使用\nclass function_demo(object): name = \u0026#34;demo\u0026#34; def run(self): return \u0026#34;hello function\u0026#34; functiondemo = function_demo() res = hasattr(functiondemo, \u0026#34;addr\u0026#34;) # 先判断是否存在 if res: addr = getattr(functiondemo, \u0026#34;addr\u0026#34;) print(addr) else: addr = getattr(functiondemo, \u0026#34;addr\u0026#34;, setattr(functiondemo, \u0026#34;addr\u0026#34;, \u0026#34;北京首都\u0026#34;)) print(addr) 14.什么是lambda函数？ 有什么好处？ lambda 函数是一个可以接收任意多个参数(包括可选参数)并且返回单个表达式值的函数\n1.lambda函数比较轻便，即用即仍，很适合需要完成一项功能，但是此功能只在此一处使用，连名字都很随意的情况下\n2.匿名函数，一般用来给filter，map这样的函数式编程服务\n3.作为回调函数，传递给某些应用，比如消息处理\n15.递归函数停止的条件？ 递归的终止条件一般定义在递归函数内部，在递归调用前要做一个条件判断，根据判断的结果选择是继续调用自身，还是return，，返回终止递归。\n终止的条件：判断递归的次数是否达到某一限定值\n2.判断运算的结果是否达到某个范围等，根据设计的目的来选择\n16.什么是lambda函数？它有什么好处？写一个匿名函数求两个数的和 lambda函数是匿名函数，使用lambda函数能创建小型匿名函数，这种函数得名于省略了用def声明函数的标准步骤\n设计模式 1.对设计模式的理解，简述你了解的设计模式？ 设计模式是经过总结，优化的，对我们经常会碰到的一些编程问题的可重用解决方案。一个设计模式并不像一个类或一个库那样能够直接作用于我们的代码，反之，设计模式更为高级，它是一种必须在特定情形下实现的一种方法模板。 常见的是工厂模式和单例模式\n2.请手写一个单例 #python2 class A(object): __instance = None def __new__(cls,*args,**kwargs): if cls.__instance is None: cls.__instance = objecet.__new__(cls) return cls.__instance else: return cls.__instance 3.单例模式的应用场景有那些？ 单例模式应用的场景一般发现在以下条件下： 资源共享的情况下，避免由于资源操作时导致的性能或损耗等，如日志文件，应用配置。 控制资源的情况下，方便资源之间的互相通信。如线程池等，1,网站的计数器 2,应用配置 3.多线程池 4数据库配置 数据库连接池 5.应用程序的日志应用\u0026hellip;\n4.对装饰器的理解，并写出一个计时器记录方法执行性能的装饰器？ 装饰器本质上是一个callable object ，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。\nimport time from functools import wraps def timeit(func): @wraps(func) def wrapper(*args, **kwargs): start = time.clock() ret = func(*args, **kwargs) end = time.clock() print(\u0026#39;used:\u0026#39;,end-start) return ret return wrapper @timeit def foo(): print(\u0026#39;in foo()\u0026#39;foo()) 5.解释以下什么是闭包？ 在函数内部再定义一个函数，并且这个函数用到了外边函数的变量，那么将这个函数以及用到的一些变量称之为闭包。\n6.函数装饰器有什么作用？ 装饰器本质上是一个callable object，它可以在让其他函数在不需要做任何代码的变动的前提下增加额外的功能。装饰器的返回值也是一个函数的对象，它经常用于有切面需求的场景。比如：插入日志，性能测试，事务处理，缓存。权限的校验等场景，有了装饰器就可以抽离出大量的与函数功能本身无关的雷同代码并发并继续使用。 详细参考：https://manjusaka.itscoder.com/2018/02/23/something-about-decorator/\n7.生成器，迭代器的区别？ 迭代器是遵循迭代协议的对象。用户可以使用 iter() 以从任何序列得到迭代器（如 list, tuple, dictionary, set 等）。另一个方法则是创建一个另一种形式的迭代器 —— generator 。要获取下一个元素，则使用成员函数 next()（Python 2）或函数 next() function （Python 3） 。当没有元素时，则引发 StopIteration 此例外。若要实现自己的迭代器，则只要实现 next()（Python 2）或 __next__()（ Python 3）\n生成器（Generator），只是在需要返回数据的时候使用yield语句。每次next()被调用时，生成器会返回它脱离的位置（它记忆语句最后一次执行的位置和所有的数据值）\n区别： 生成器能做到迭代器能做的所有事，而且因为自动创建iter()和next()方法，生成器显得特别简洁，而且生成器也是高效的，使用生成器表达式取代列表解析可以同时节省内存。除了创建和保存程序状态的自动方法，当发生器终结时，还会自动抛出StopIteration异常。\n官方介绍：https://docs.python.org/3/tutorial/classes.html#iterators\n8.Python中yield的用法? yield就是保存当前程序执行状态。你用for循环的时候，每次取一个元素的时候就会计算一次。用yield的函数叫generator,和iterator一样，它的好处是不用一次计算所有元素，而是用一次算一次，可以节省很多空间，generator每次计算需要上一次计算结果，所以用yield,否则一return，上次计算结果就没了\n面向对象 1.Python中的可变对象和不可变对象？ 不可变对象，该对象所指向的内存中的值不能被改变。当改变某个变量时候，由于其所指的值不能被改变，相当于把原来的值复制一份后再改变，这会开辟一个新的地址，变量再指向这个新的地址。\n可变对象，该对象所指向的内存中的值可以被改变。变量（准确的说是引用）改变后，实际上其所指的值直接发生改变，并没有发生复制行为，也没有开辟出新的地址，通俗点说就是原地改变。\nPyhton中，数值类型(int 和float)，字符串str、元组tuple都是不可变类型。而列表list、字典dict、集合set是可变类型\n2.Python的魔法方法 魔法方法就是可以给你的类增加魔力的特殊方法，如果你的对象实现（重载）了这些方法中的某一个，那么这个方法就会在特殊的情况下被Python所调用，你可以定义自己想要的行为，而这一切都是自动发生的，它们经常是两个下划线包围来命名的（比如__init___,__len__),Python的魔法方法是非常强大的所以了解其使用方法也变得尤为重要!\n__init__构造器，当一个实例被创建的时候初始化的方法，但是它并不是实例化调用的第一个方法。\n__new__才是实例化对象调用的第一个方法，它只取下cls参数，并把其他参数传给__init___.\n___new__很少使用，但是也有它适合的场景，尤其是当类继承自一个像元组或者字符串这样不经常改变的类型的时候。\n__call__让一个类的实例像函数一样被调用\n__getitem__定义获取容器中指定元素的行为，相当于self[key]\n__getattr__定义当用户试图访问一个不存在属性的时候的行为。\n__setattr__定义当一个属性被设置的时候的行为\n__getattribute___定义当一个属性被访问的时候的行为\n3.面向对象中怎么实现只读属性? 将对象私有化，通过共有方法提供一个读取数据的接口\nclass person: def __init__(self, x): self.__age = 10 def age(self): return self.__age t = person(22) # t.__age =100 print(t.age()) 最好的方法\nclass MyCls(object): __weight = 50 @property def weight(self): return self.__weight 4.谈谈你对面向对象的理解？ 面向对象是相当于面向过程而言的，面向过程语言是一种基于功能分析的，以算法为中心的程序设计方法，而面向对象是一种基于结构分析的，以数据为中心的程序设计思想。在面向对象语言中有一个很重要的东西，叫做类。面向对象有三大特性：封装、继承、多态。\n5.Python字符串查找和替换？ a、str.find()：正序字符串查找函数 函数原型： str.find(substr [,pos_start [,pos_end ] ] ) 返回str中第一次出现的substr的第一个字母的标号，如果str中没有substr则返回-1，也就是说从左边算起的第一次出现的substr的首字母标号。 参数说明： str：代表原字符串 substr：代表要查找的字符串 pos_start：代表查找的开始位置，默认是从下标0开始查找 pos_end：代表查找的结束位置 例子： 'aabbcc.find('bb')' # 2 b、str.index()：正序字符串查找函数 index()函数类似于find()函数，在Python中也是在字符串中查找子串第一次出现的位置，跟find()不同的是，未找到则抛出异常。 函数原型： str.index(substr [, pos_start, [ pos_end ] ] ) 参数说明： str：代表原字符串 substr：代表要查找的字符串 pos_start：代表查找的开始位置，默认是从下标0开始查找 pos_end：代表查找的结束位置 例子： 'acdd l1 23'.index(' ') # 4 c、str.rfind()：倒序字符串查找函数 函数原型： str.rfind( substr [, pos_start [,pos_ end ] ]) 返回str中最后出现的substr的第一个字母的标号，如果str中没有substr则返回-1，也就是说从右边算起的第一次出现的substr的首字母标号。 参数说明： str：代表原字符串 substr：代表要查找的字符串 pos_start：代表查找的开始位置，默认是从下标0开始查找 pos_end：代表查找的结束位置 例子： 'adsfddf'.rfind('d') # 5 d、str.rindex()：倒序字符串查找函数 rindex()函数类似于rfind()函数，在Python中也是在字符串中倒序查找子串最后一次出现的位置，跟rfind()不同的是，未找到则抛出异常。 函数原型： str.rindex(substr [, pos_start, [ pos_end ] ] ) 参数说明： str：代表原字符串 substr：代表要查找的字符串 pos_start：代表查找的开始位置，默认是从下标0开始查找 pos_end：代表查找的结束位置 例子： 'adsfddf'.rindex('d') # 5 e、使用re模块进行查找和替换： 函数 说明 re.match(pat, s) 只从字符串s的头开始匹配，比如(‘123’, ‘12345’)匹配上了，而(‘123’,’01234’)就是没有匹配上，没有匹配上返回None，匹配上返回matchobject re.search(pat, s) 从字符串s的任意位置都进行匹配，比如(‘123’,’01234’)就是匹配上了，只要s只能存在符合pat的连续字符串就算匹配上了，没有匹配上返回None，匹配上返回matchobject re.sub(pat,newpat,s) re.sub(pat,newpat,s)\t对字符串中s的包含的所有符合pat的连续字符串进行替换，如果newpat为str,那么就是替换为newpat,如果newpat是函数，那么就按照函数返回值替换。sub函数两个有默认值的参数分别是count表示最多只处理前几个匹配的字符串，默认为0表示全部处理；最后一个是flags，默认为0 f、使用replace()进行替换： 基本用法：对象.replace(rgExp,replaceText,max) 其中，rgExp和replaceText是必须要有的，max是可选的参数，可以不加。 rgExp是指正则表达式模式或可用标志的正则表达式对象，也可以是 String 对象或文字； replaceText是一个String 对象或字符串文字； max是一个数字。 对于一个对象，在对象的每个rgExp都替换成replaceText，从左到右最多max次。 s1='hello world' s1.replace('world','liming') 6.用Python匹配HTML tag的时候，\u0026lt;.\u0026gt; 和 \u0026lt;.?\u0026gt; 有什么区别 第一个代表贪心匹配，第二个代表非贪心； ?在一般正则表达式里的语法是指的\u0026quot;零次或一次匹配左边的字符或表达式\u0026quot;相当于{0,1} 而当?后缀于*,+,?,{n},{n,},{n,m}之后，则代表非贪心匹配模式，也就是说，尽可能少的匹配左边的字符或表达式，这里是尽可能少的匹配.(任意字符) 所以：第一种写法是，尽可能多的匹配，就是匹配到的字符串尽量长，第二中写法是尽可能少的匹配，就是匹配到的字符串尽量短。 比如\u0026lt;tag\u0026gt;tag\u0026gt;tag\u0026gt;end，第一个会匹配\u0026lt;tag\u0026gt;tag\u0026gt;tag\u0026gt;,第二个会匹配\u0026lt;tag\u0026gt;。 7.正则表达式贪婪与非贪婪模式的区别？ 贪婪模式： 定义：正则表达式去匹配时，会尽量多的匹配符合条件的内容 标识符：+，?，*，{n}，{n,}，{n,m} 匹配时，如果遇到上述标识符，代表是贪婪匹配，会尽可能多的去匹配内容 非贪婪模式： 定义：正则表达式去匹配时，会尽量少的匹配符合条件的内容 也就是说，一旦发现匹配符合要求，立马就匹配成功，而不会继续匹配下去(除非有g，开启下一组匹配) 标识符：+?，??，*?，{n}?，{n,}?，{n,m}? 可以看到，非贪婪模式的标识符很有规律，就是贪婪模式的标识符后面加上一个? 参考文章：https://dailc.github.io/2017/07/06/regularExpressionGreedyAndLazy.html 8.怎么过滤评论中的表情？ 思路：主要是匹配表情包的范围，将表情包的范围用空替换掉 import re pattern = re.compile(u\u0026#39;[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]\u0026#39;) pattern.sub(\u0026#39;\u0026#39;,text) 9.简述Python里面search和match的区别 match()函数只检测字符串开头位置是否匹配，匹配成功才会返回结果，否则返回None； search()函数会在整个字符串内查找模式匹配,只到找到第一个匹配然后返回一个包含匹配信息的对象,该对象可以通过调用group()方法得到匹配的字符串,如果字符串没有匹配，则返回None。 系统编程 1.进程总结 进程：程序运行在操作系统上的一个实例，就称之为进程。进程需要相应的系统资源：内存、时间片、pid。 创建进程： 首先要导入multiprocessing中的Process： 创建一个Process对象; 创建Process对象时，可以传递参数;\np = Process(target=XXX,args=(tuple,),kwargs={key:value}) target = XXX 指定的任务函数，不用加(), args=(tuple,)kwargs={key:value}给任务函数传递的参数 使用start()启动进程 结束进程 给子进程指定函数传递参数Demo\nimport os from mulitprocessing import Process import time def pro_func(name,age,**kwargs): for i in range(5): print(\u0026#34;子进程正在运行中，name=%s,age=%d,pid=%d\u0026#34;%(name,age,os.getpid())) print(kwargs) time.sleep(0.2) if __name__ ==\u0026#34;__main__\u0026#34;: #创建Process对象 p = Process(target=pro_func,args=(\u0026#39;小明\u0026#39;,18),kwargs={\u0026#39;m\u0026#39;:20}) #启动进程 p.start() time.sleep(1) #1秒钟之后，立刻结束子进程 p.terminate() p.join() 注意：进程间不共享全局变量\n进程之间的通信-Queue\n在初始化Queue()对象时（例如q=Queue(),若在括号中没有指定最大可接受的消息数量，获数量为负值时，那么就代表可接受的消息数量没有上限一直到内存尽头）\nQueue.qsize():返回当前队列包含的消息数量\nQueue.empty():如果队列为空，返回True，反之False\nQueue.full():如果队列满了，返回True,反之False\nQueue.get([block[,timeout]]):获取队列中的一条消息，然后将其从队列中移除，\nblock默认值为True。\n如果block使用默认值，且没有设置timeout（单位秒),消息队列如果为空，此时程序将被阻塞（停在读中状态），直到消息队列读到消息为止，如果设置了timeout，则会等待timeout秒，若还没读取到任何消息，则抛出“Queue.Empty\u0026quot;异常：\nQueue.get_nowait()相当于Queue.get(False)\nQueue.put(item,[block[,timeout]]):将item消息写入队列，block默认值为True; 如果block使用默认值，且没有设置timeout（单位秒），消息队列如果已经没有空间可写入，此时程序将被阻塞（停在写入状态），直到从消息队列腾出空间为止，如果设置了timeout，则会等待timeout秒，若还没空间，则抛出”Queue.Full\u0026quot;异常 如果block值为False，消息队列如果没有空间可写入，则会立刻抛出\u0026quot;Queue.Full\u0026quot;异常; Queue.put_nowait(item):相当Queue.put(item,False)\n进程间通信Demo:\nfrom multiprocessing import Process.Queue import os,time,random #写数据进程执行的代码： def write(q): for value in [\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;,\u0026#39;C\u0026#39;]: print(\u0026#34;Put %s to queue...\u0026#34;,%value) q.put(value) time.sleep(random.random()) #读数据进程执行的代码 def read(q): while True: if not q.empty(): value = q.get(True) print(\u0026#34;Get %s from queue.\u0026#34;,%value) time.sleep(random.random()) else: break if __name__==\u0026#39;__main__\u0026#39;: #父进程创建Queue，并传给各个子进程 q = Queue() pw = Process(target=write,args=(q,)) pr = Process(target=read,args=(q,)) #启动子进程pw ，写入： pw.start() #等待pw结束 pw.join() #启动子进程pr，读取： pr.start() pr.join() #pr 进程里是死循环，无法等待其结束，只能强行终止: print(\u0026#39;\u0026#39;) print(\u0026#39;所有数据都写入并且读完\u0026#39;) 进程池Pool #coding:utf-8 from multiprocessing import Pool import os,time,random def worker(msg): t_start = time.time() print(\u0026#34;%s 开始执行，进程号为%d\u0026#34;%(msg,os.getpid())) # random.random()随机生成0-1之间的浮点数 time.sleep(random.random()*2) t_stop = time.time() print(msg,\u0026#34;执行完毕，耗时%0.2f”%（t_stop-t_start)) po = Pool(3)#定义一个进程池，最大进程数3 for i in range(0,10): po.apply_async(worker,(i,)) print(\u0026#34;---start----\u0026#34;) po.close() po.join() print(\u0026#34;----end----\u0026#34;) 进程池中使用Queue\n如果要使用Pool创建进程，就需要使用multiprocessing.Manager()中的Queue(),而不是multiprocessing.Queue(),否则会得到如下的错误信息：\nRuntimeError： Queue objects should only be shared between processs through inheritance\nfrom multiprocessing import Manager,Pool import os,time,random def reader(q): print(\u0026#34;reader 启动(%s),父进程为（%s)\u0026#34;%(os.getpid(),os.getpid())) for i in range(q.qsize()): print(\u0026#34;reader 从Queue获取到消息:%s\u0026#34;%q.get(True)) def writer(q): print(\u0026#34;writer 启动（%s),父进程为(%s)\u0026#34;%(os.getpid(),os.getpid())) for i in \u0026#34;itcast\u0026#34;: q.put(i) if __name__ == \u0026#34;__main__\u0026#34;: print(\u0026#34;(%s)start\u0026#34;%os.getpid()) q = Manager().Queue()#使用Manager中的Queue po = Pool() po.apply_async(wrtier,(q,)) time.sleep(1) po.apply_async(reader,(q,)) po.close() po.join() print(\u0026#34;(%s)End\u0026#34;%os.getpid()) 2.谈谈你对多进程，多线程，以及协程的理解，项目是否用？ 这个问题被问的概念相当之大， 进程：一个运行的程序（代码）就是一个进程，没有运行的代码叫程序，进程是系统资源分配的最小单位，进程拥有自己独立的内存空间，所有进程间数据不共享，开销大。\n线程: cpu调度执行的最小单位，也叫执行路径，不能独立存在，依赖进程存在，一个进程至少有一个线程，叫主线程，而多个线程共享内存（数据共享，共享全局变量),从而极大地提高了程序的运行效率。\n协程: 是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操中栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。\n3.Python异步使用场景有那些？ 异步的使用场景:\n1、 不涉及共享资源，获对共享资源只读，即非互斥操作\n2、 没有时序上的严格关系\n3、 不需要原子操作，或可以通过其他方式控制原子性\n4、 常用于IO操作等耗时操作，因为比较影响客户体验和使用性能\n5、 不影响主线程逻辑\n4.多线程共同操作同一个数据互斥锁同步？ import threading import time class MyThread(threading.Thread): def run(self): global num time.sleep(1) if mutex.acquire(1): num +=1 msg = self.name + \u0026#39;set num to \u0026#39; +str(num) print msg mutex.release() num = 0 mutex = threading.Lock() def test(): for i in range(5): t = MyThread() t.start() if __name__==\u0026#34;__main__\u0026#34;: test() 5.什么是多线程竞争？ 线程是非独立的，同一个进程里线程是数据共享的，当各个线程访问数据资源时会出现竞争状态即：数据几乎同步会被多个线程占用，造成数据混乱，即所谓的线程不安全\n那么怎么解决多线程竞争问题？\u0026mdash;锁\n锁的好处： 确保了某段关键代码（共享数据资源）只能由一个线程从头到尾完整地执行能解决多线程资源竞争下的原子操作问题。\n锁的坏处： 阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了\n锁的致命问题: 死锁\n6.请介绍一下Python的线程同步？ 一、 setDaemon(False) 当一个进程启动之后，会默认产生一个主线程，因为线程是程序执行的最小单位，当设置多线程时，主线程会创建多个子线程，在Python中，默认情况下就是setDaemon(False),主线程执行完自己的任务以后，就退出了，此时子线程会继续执行自己的任务，直到自己的任务结束。\n例子\nimport threading import time def thread(): time.sleep(2) print(\u0026#39;---子线程结束---\u0026#39;) def main(): t1 = threading.Thread(target=thread) t1.start() print(\u0026#39;---主线程--结束\u0026#39;) if __name__ ==\u0026#39;__main__\u0026#39;: main() #执行结果 ---主线程--结束 ---子线程结束--- 二、 setDaemon（True) 当我们使用setDaemon(True)时，这是子线程为守护线程，主线程一旦执行结束，则全部子线程被强制终止\n例子\nimport threading import time def thread(): time.sleep(2) print(’---子线程结束---\u0026#39;) def main(): t1 = threading.Thread(target=thread) t1.setDaemon(True)#设置子线程守护主线程 t1.start() print(\u0026#39;---主线程结束---\u0026#39;) if __name__ ==\u0026#39;__main__\u0026#39;: main() #执行结果 ---主线程结束--- #只有主线程结束，子线程来不及执行就被强制结束 三、 join（线程同步) join 所完成的工作就是线程同步，即主线程任务结束以后，进入堵塞状态，一直等待所有的子线程结束以后，主线程再终止。\n当设置守护线程时，含义是主线程对于子线程等待timeout的时间将会杀死该子线程，最后退出程序，所以说，如果有10个子线程，全部的等待时间就是每个timeout的累加和，简单的来说，就是给每个子线程一个timeou的时间，让他去执行，时间一到，不管任务有没有完成，直接杀死。\n没有设置守护线程时，主线程将会等待timeout的累加和这样的一段时间，时间一到，主线程结束，但是并没有杀死子线程，子线程依然可以继续执行，直到子线程全部结束，程序退出。\n例子\nimport threading import time def thread(): time.sleep(2) print(\u0026#39;---子线程结束---\u0026#39;) def main(): t1 = threading.Thread(target=thread) t1.setDaemon(True) t1.start() t1.join(timeout=1)#1 线程同步，主线程堵塞1s 然后主线程结束，子线程继续执行 #2 如果不设置timeout参数就等子线程结束主线程再结束 #3 如果设置了setDaemon=True和timeout=1主线程等待1s后会强制杀死子线程，然后主线程结束 print(\u0026#39;---主线程结束---\u0026#39;) if __name__==\u0026#39;__main___\u0026#39;: main() 7.解释以下什么是锁，有哪几种锁？ 锁(Lock)是python提供的对线程控制的对象。有互斥锁，可重入锁，死锁。\n8.什么是死锁？ 若干子线程在系统资源竞争时，都在等待对方对某部分资源解除占用状态，结果是谁也不愿先解锁，互相干等着，程序无法执行下去，这就是死锁。\nGIL锁 全局解释器锁\n作用： 限制多线程同时执行，保证同一时间只有一个线程执行，所以cython里的多线程其实是伪多线程！\n所以python里常常使用协程技术来代替多线程，协程是一种更轻量级的线程。\n进程和线程的切换时由系统决定，而协程由我们程序员自己决定，而模块gevent下切换是遇到了耗时操作时才会切换\n三者的关系：进程里有线程，线程里有协程。\n9.多线程交互访问数据，如果访问到了就不访问了？ 怎么避免重读？\n创建一个已访问数据列表，用于存储已经访问过的数据，并加上互斥锁，在多线程访问数据的时候先查看数据是否在已访问的列表中，若已存在就直接跳过。\n10.什么是线程安全，什么是互斥锁？ 每个对象都对应于一个可称为’互斥锁‘的标记，这个标记用来保证在任一时刻，只能有一个线程访问该对象。\n同一进程中的多线程之间是共享系统资源的，多个线程同时对一个对象进行操作，一个线程操作尚未结束，另一线程已经对其进行操作，导致最终结果出现错误，此时需要对被操作对象添加互斥锁，保证每个线程对该对象的操作都得到正确的结果。\n11.说说下面几个概念：同步，异步，阻塞，非阻塞？ 同步： 多个任务之间有先后顺序执行，一个执行完下个才能执行。\n异步： 多个任务之间没有先后顺序，可以同时执行，有时候一个任务可能要在必要的时候获取另一个同时执行的任务的结果，这个就叫回调！\n阻塞： 如果卡住了调用者，调用者不能继续往下执行，就是说调用者阻塞了。\n非阻塞： 如果不会卡住，可以继续执行，就是说非阻塞的。\n同步异步相对于多任务而言，阻塞非阻塞相对于代码执行而言。\n12.什么是僵尸进程和孤儿进程？怎么避免僵尸进程？ 孤儿进程： 父进程退出，子进程还在运行的这些子进程都是孤儿进程，孤儿进程将被init 进程（进程号为1）所收养，并由init 进程对他们完成状态收集工作。\n僵尸进程： 进程使用fork 创建子进程，如果子进程退出，而父进程并没有调用wait 获waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。\n避免僵尸进程的方法：\n1.fork 两次用孙子进程去完成子进程的任务\n2.用wait()函数使父进程阻塞\n3.使用信号量，在signal handler 中调用waitpid,这样父进程不用阻塞\n13.python中进程与线程的使用场景？ 多进程适合在CPU密集操作（cpu操作指令比较多，如位多的的浮点运算）。\n多线程适合在IO密性型操作（读写数据操作比多的的，比如爬虫）\n14.线程是并发还是并行，进程是并发还是并行？ 线程是并发，进程是并行;\n进程之间互相独立，是系统分配资源的最小单位，同一个进程中的所有线程共享资源。\n15.并行(parallel)和并发（concurrency)? 并行： 同一时刻多个任务同时在运行\n并发：不会在同一时刻同时运行，存在交替执行的情况。\n实现并行的库有： multiprocessing\n实现并发的库有: threading\n程序需要执行较多的读写、请求和回复任务的需要大量的IO操作，IO密集型操作使用并发更好。\nCPU运算量大的程序，使用并行会更好\n16.IO密集型和CPU密集型区别？ IO密集型： 系统运行，大部分的状况是CPU在等 I/O（硬盘/内存）的读/写\nCPU密集型： 大部分时间用来做计算，逻辑判断等CPU动作的程序称之CPU密集型。\n17.python asyncio的原理？ asyncio这个库就是使用python的yield这个可以打断保存当前函数的上下文的机制， 封装好了selector 摆脱掉了复杂的回调关系\n网络编程 1.怎么实现强行关闭客户端和服务器之间的连接? 2.简述TCP和UDP的区别以及优缺点? 3.简述浏览器通过WSGI请求动态资源的过程? 浏览器发送的请求被Nginx监听到，Nginx根据请求的URL的PATH或者后缀把请求静态资源的分发到静态资源的目录，别的请求根据配置好的转发到相应端口。 实现了WSGI的程序会监听某个端口，监听到Nginx转发过来的请求接收后(一般用socket的recv来接收HTTP的报文)以后把请求的报文封装成environ的字典对象，然后再提供一个start_response的方法。把这两个对象当成参数传入某个方法比如wsgi_app(environ, start_response)或者实现了__call__(self, environ, start_response)方法的某个实例。这个实例再调用start_response返回给实现了WSGI的中间件，再由中间件返回给Nginx。\n4.描述用浏览器访问www.baidu.com的过程 5.Post和Get请求的区别? 6.cookie 和session 的区别？ 7.列出你知道的HTTP协议的状态码，说出表示什么意思？ 8.请简单说一下三次握手和四次挥手？ 9.说一下什么是tcp的2MSL？ 10.为什么客户端在TIME-WAIT状态必须等待2MSL的时间？ 11.说说HTTP和HTTPS区别？ 12.谈一下HTTP协议以及协议头部中表示数据类型的字段？ 13.HTTP请求方法都有什么？ 14.使用Socket套接字需要传入哪些参数 ？ 15.HTTP常见请求头？ 16.七层模型？ 17.url的形式？ Web Flask 1.对Flask蓝图(Blueprint)的理解？ 蓝图的定义\n蓝图 /Blueprint 是Flask应用程序组件化的方法，可以在一个应用内或跨越多个项目共用蓝图。使用蓝图可以极大简化大型应用的开发难度，也为Flask扩展提供了一种在应用中注册服务的集中式机制。\n蓝图的应用场景：\n把一个应用分解为一个蓝图的集合。这对大型应用是理想的。一个项目可以实例化一个应用对象，初始化几个扩展，并注册一集合的蓝图。\n以URL前缀和/或子域名，在应用上注册一个蓝图。URL前缀/子域名中的参数即成为这个蓝图下的所有视图函数的共同的视图参数（默认情况下） 在一个应用中用不同的URL规则多次注册一个蓝图。\n通过蓝图提供模板过滤器、静态文件、模板和其他功能。一个蓝图不一定要实现应用或视图函数。\n初始化一个Flask扩展时，在这些情况中注册一个蓝图。\n蓝图的缺点：\n不能在应用创建后撤销注册一个蓝图而不销毁整个应用对象。\n使用蓝图的三个步骤\n1.创建一个蓝图对象\nblue = Blueprint(\u0026#34;blue\u0026#34;,__name__) 2.在这个蓝图对象上进行操作，例如注册路由、指定静态文件夹、注册模板过滤器\u0026hellip;\n@blue.route(\u0026#39;/\u0026#39;) def blue_index(): return \u0026#34;Welcome to my blueprint\u0026#34; 3.在应用对象上注册这个蓝图对象\napp.register_blueprint(blue,url_prefix=\u0026#34;/blue\u0026#34;) 2.Flask 和 Django 路由映射的区别？ 在django中，路由是浏览器访问服务器时，先访问的项目中的url，再由项目中的url找到应用中url，这些url是放在一个列表里，遵从从前往后匹配的规则。在flask中，路由是通过装饰器给每个视图函数提供的，而且根据请求方式的不同可以一个url用于不同的作用。\nDjango 1.什么是wsgi,uwsgi,uWSGI? WSGI:\nweb服务器网关接口，是一套协议。用于接收用户请求并将请求进行初次封装，然后将请求交给web框架。\n实现wsgi协议的模块：wsgiref,本质上就是编写一socket服务端，用于接收用户请求（django)\nwerkzeug,本质上就是编写一个socket服务端，用于接收用户请求(flask)\nuwsgi:\n与WSGI一样是一种通信协议，它是uWSGI服务器的独占协议，用于定义传输信息的类型。 uWSGI:\n是一个web服务器，实现了WSGI的协议，uWSGI协议，http协议\n2.Django、Flask、Tornado的对比？ 1、 Django走的大而全的方向，开发效率高。它的MTV框架，自带的ORM,admin后台管理,自带的sqlite数据库和开发测试用的服务器，给开发者提高了超高的开发效率。 重量级web框架，功能齐全，提供一站式解决的思路，能让开发者不用在选择上花费大量时间。\n自带ORM和模板引擎，支持jinja等非官方模板引擎。\n自带ORM使Django和关系型数据库耦合度高，如果要使用非关系型数据库，需要使用第三方库\n自带数据库管理app\n成熟，稳定，开发效率高，相对于Flask，Django的整体封闭性比较好，适合做企业级网站的开发。python web框架的先驱，第三方库丰富\n2、 Flask 是轻量级的框架，自由，灵活，可扩展性强，核心基于Werkzeug WSGI工具 和jinja2 模板引擎\n适用于做小网站以及web服务的API,开发大型网站无压力，但架构需要自己设计\n与关系型数据库的结合不弱于Django，而与非关系型数据库的结合远远优于Django\n3、 Tornado走的是少而精的方向，性能优越，它最出名的异步非阻塞的设计方式\nTornado的两大核心模块：\niostraem:对非阻塞的socket进行简单的封装\nioloop: 对I/O 多路复用的封装,它实现一个单例\n3.CORS 和 CSRF的区别？ 什么是CORS？\nCORS是一个W3C标准,全称是“跨域资源共享\u0026quot;(Cross-origin resoure sharing). 它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。\n什么是CSRF？\nCSRF主流防御方式是在后端生成表单的时候生成一串随机token,内置到表单里成为一个字段，同时，将此串token置入session中。每次表单提交到后端时都会检查这两个值是否一致，以此来判断此次表单提交是否是可信的，提交过一次之后，如果这个页面没有生成CSRF token,那么token将会被清空,如果有新的需求，那么token会被更新。 攻击者可以伪造POST表单提交，但是他没有后端生成的内置于表单的token，session中没有token都无济于事。\n4.Session,Cookie,JWT的理解 为什么要使用会话管理\n众所周知，HTTP协议是一个无状态的协议，也就是说每个请求都是一个独立的请求，请求与请求之间并无关系。但在实际的应用场景，这种方式并不能满足我们的需求。举个大家都喜欢用的例子，把商品加入购物车，单独考虑这个请求，服务端并不知道这个商品是谁的，应该加入谁的购物车？因此这个请求的上下文环境实际上应该包含用户的相关信息，在每次用户发出请求时把这一小部分额外信息，也做为请求的一部分，这样服务端就可以根据上下文中的信息，针对具体的用户进行操作。所以这几种技术的出现都是对HTTP协议的一个补充，使得我们可以用HTTP协议+状态管理构建一个的面向用户的WEB应用。\nSession 和Cookie的区别\n这里我想先谈谈session与cookies,因为这两个技术是做为开发最为常见的。那么session与cookies的区别是什么？个人认为session与cookies最核心区别在于额外信息由谁来维护。利用cookies来实现会话管理时，用户的相关信息或者其他我们想要保持在每个请求中的信息，都是放在cookies中,而cookies是由客户端来保存，每当客户端发出新请求时，就会稍带上cookies,服务端会根据其中的信息进行操作。 当利用session来进行会话管理时，客户端实际上只存了一个由服务端发送的session_id,而由这个session_id,可以在服务端还原出所需要的所有状态信息，从这里可以看出这部分信息是由服务端来维护的。\n除此以外，session与cookies都有一些自己的缺点：\ncookies的安全性不好，攻击者可以通过获取本地cookies进行欺骗或者利用cookies进行CSRF攻击。使用cookies时,在多个域名下，会存在跨域问题。 session 在一定的时间里，需要存放在服务端，因此当拥有大量用户时，也会大幅度降低服务端的性能，当有多台机器时，如何共享session也会是一个问题.(redis集群)也就是说，用户第一个访问的时候是服务器A，而第二个请求被转发给了服务器B，那服务器B如何得知其状态。实际上，session与cookies是有联系的，比如我们可以把session_id存放在cookies中的。\nJWT是如何工作的\n首先用户发出登录请求，服务端根据用户的登录请求进行匹配，如果匹配成功，将相关的信息放入payload中，利用算法，加上服务端的密钥生成token，这里需要注意的是secret_key很重要，如果这个泄露的话，客户端就可以随机篡改发送的额外信息，它是信息完整性的保证。生成token后服务端将其返回给客户端，客户端可以在下次请求时，将token一起交给服务端，一般是说我们可以将其放在Authorization首部中，这样也就可以避免跨域问题。\n5.简述Django请求生命周期 一般是用户通过浏览器向我们的服务器发起一个请求(request),这个请求会去访问视图函数，如果不涉及到数据调用，那么这个时候视图函数返回一个模板也就是一个网页给用户） 视图函数调用模型毛模型去数据库查找数据，然后逐级返回，视图函数把返回的数据填充到模板中空格中，最后返回网页给用户。\n1.wsgi ,请求封装后交给web框架（Flask，Django)\n2.中间件，对请求进行校验或在请求对象中添加其他相关数据，例如：csrf,request.session\n3.路由匹配 根据浏览器发送的不同url去匹配不同的视图函数\n4.视图函数，在视图函数中进行业务逻辑的处理，可能涉及到：orm，templates\n5.中间件，对响应的数据进行处理\n6.wsgi，将响应的内容发送给浏览器\n6.用的restframework完成api发送时间时区 当前的问题是用django的rest framework模块做一个get请求的发送时间以及时区信息的api\nclass getCurrenttime(APIView): def get(self,request): local_time = time.localtime() time_zone =settings.TIME_ZONE temp = {\u0026#39;localtime\u0026#39;:local_time,\u0026#39;timezone\u0026#39;:time_zone} return Response(temp) 7.nginx,tomcat,apach到都是什么？ Nginx（engine x)是一个高性能的HTTP和反向代理服务器，也是 一个IMAP/POP3/SMTP服务器，工作在OSI七层，负载的实现方式：轮询，IP_HASH,fair,session_sticky. Apache HTTP Server是一个模块化的服务器，源于NCSAhttpd服务器 Tomcat 服务器是一个免费的开放源代码的Web应用服务器，属于轻量级应用服务器，是开发和调试JSP程序的首选。\n8.请给出你熟悉关系数据库范式有哪些，有什么作用？ 在进行数据库的设计时，所遵循的一些规范，只要按照设计规范进行设计，就能设计出没有数据冗余和数据维护异常的数据库结构。\n数据库的设计的规范有很多，通常来说我们在设是数据库时只要达到其中一些规范就可以了，这些规范又称之为数据库的三范式，一共有三条，也存在着其他范式，我们只要做到满足前三个范式的要求，就能设陈出符合我们的数据库了，我们也不能全部来按照范式的要求来做，还要考虑实际的业务使用情况，所以有时候也需要做一些违反范式的要求。 1.数据库设计的第一范式(最基本)，基本上所有数据库的范式都是符合第一范式的，符合第一范式的表具有以下几个特点：\n数据库表中的所有字段都只具有单一属性，单一属性的列是由基本的数据类型（整型，浮点型，字符型等）所构成的设计出来的表都是简单的二比表\n2.数据库设计的第二范式(是在第一范式的基础上设计的)，要求一个表中只具有一个业务主键，也就是说符合第二范式的表中不能存在非主键列对只对部分主键的依赖关系\n3.数据库设计的第三范式，指每一个非主属性既不部分依赖与也不传递依赖于业务主键，也就是第二范式的基础上消除了非主属性对主键的传递依赖\n9.简述QQ登陆过程 qq登录，在我们的项目中分为了三个接口，\n第一个接口是请求qq服务器返回一个qq登录的界面;\n第二个接口是通过扫码或账号登陆进行验证，qq服务器返回给浏览器一个code和state,利用这个code通过本地服务器去向qq服务器获取access_token覆返回给本地服务器，凭借access_token再向qq服务器获取用户的openid(openid用户的唯一标识)\n第三个接口是判断用户是否是第一次qq登录，如果不是的话直接登录返回的jwt-token给用户，对没有绑定过本网站的用户，对openid进行加密生成token进行绑定\n10.post 和 get的区别? 1.GET是从服务器上获取数据，POST是向服务器传送数据\n2.在客户端，GET方式在通过URL提交数据，数据在URL中可以看到，POST方式，数据放置在HTML——HEADER内提交\n3.对于GET方式，服务器端用Request.QueryString获取变量的值，对于POST方式，服务器端用Request.Form获取提交的数据\n11.项目中日志的作用 一、日志相关概念\n1.日志是一种可以追踪某些软件运行时所发生事件的方法\n2.软件开发人员可以向他们的代码中调用日志记录相关的方法来表明发生了某些事情\n3.一个事件可以用一个包含可选变量数据的消息来描述\n4.此外，事件也有重要性的概念，这个重要性也可以被成为严重性级别(level)\n二、日志的作用\n1.通过log的分析，可以方便用户了解系统或软件、应用的运行情况;\n2.如果你的应用log足够丰富，可以分析以往用户的操作行为、类型喜好，地域分布或其他更多信息;\n3.如果一个应用的log同时也分了多个级别，那么可以很轻易地分析得到该应用的健康状况，及时发现问题并快速定位、解决问题，补救损失。\n4.简单来讲就是我们通过记录和分析日志可以了解一个系统或软件程序运行情况是否正常，也可以在应用程序出现故障时快速定位问题。不仅在开发中，在运维中日志也很重要，日志的作用也可以简单。总结为以下几点：\n1.程序调试\n2.了解软件程序运行情况，是否正常\n3,软件程序运行故障分析与问题定位\n4,如果应用的日志信息足够详细和丰富，还可以用来做用户行为分析\n12.django中间件的使用？ Django在中间件中预置了六个方法，这六个方法的区别在于不同的阶段执行，对输入或输出进行干预，方法如下：\n1.初始化：无需任何参数，服务器响应第一个请求的时候调用一次，用于确定是否启用当前中间件\ndef __init__(): pass 2.处理请求前：在每个请求上调用，返回None或HttpResponse对象。\ndef process_request(request): pass 3.处理视图前:在每个请求上调用，返回None或HttpResponse对象。\ndef process_view(request,view_func,view_args,view_kwargs): pass 4.处理模板响应前：在每个请求上调用，返回实现了render方法的响应对象。\ndef process_template_response(request,response): pass 5.处理响应后：所有响应返回浏览器之前被调用，在每个请求上调用，返回HttpResponse对象。\ndef process_response(request,response): pass 6.异常处理：当视图抛出异常时调用，在每个请求上调用，返回一个HttpResponse对象。\ndef process_exception(request,exception): pass 13.谈一下你对uWSGI和nginx的理解？ 1.uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。Nginx中HttpUwsgiModule的作用是与uWSGI服务器进行交换。WSGI是一种Web服务器网关接口。它是一个Web服务器（如nginx，uWSGI等服务器）与web应用（如用Flask框架写的程序）通信的一种规范。\n要注意WSGI/uwsgi/uWSGI这三个概念的区分。\nWSGI是一种通信协议。\nuwsgi是一种线路协议而不是通信协议，在此常用于在uWSGI服务器与其他网络服务器的数据通信。\nuWSGI是实现了uwsgi和WSGI两种协议的Web服务器。\nnginx 是一个开源的高性能的HTTP服务器和反向代理：\n1.作为web服务器，它处理静态文件和索引文件效果非常高\n2.它的设计非常注重效率，最大支持5万个并发连接，但只占用很少的内存空间\n3.稳定性高，配置简洁。\n4.强大的反向代理和负载均衡功能，平衡集群中各个服务器的负载压力应用\n14.Python中三大框架各自的应用场景？ django:主要是用来搞快速开发的，他的亮点就是快速开发，节约成本，,如果要实现高并发的话，就要对django进行二次开发，比如把整个笨重的框架给拆掉自己写socket实现http的通信,底层用纯c,c++写提升效率，ORM框架给干掉，自己编写封装与数据库交互的框架,ORM虽然面向对象来操作数据库，但是它的效率很低，使用外键来联系表与表之间的查询; flask: 轻量级，主要是用来写接口的一个框架，实现前后端分离，提考开发效率，Flask本身相当于一个内核，其他几乎所有的功能都要用到扩展(邮件扩展Flask-Mail，用户认证Flask-Login),都需要用第三方的扩展来实现。比如可以用Flask-extension加入ORM、文件上传、身份验证等。Flask没有默认使用的数据库，你可以选择MySQL，也可以用NoSQL。\n其WSGI工具箱用Werkzeug(路由模块)，模板引擎则使用Jinja2,这两个也是Flask框架的核心。\nTornado： Tornado是一种Web服务器软件的开源版本。Tornado和现在的主流Web服务器框架（包括大多数Python的框架）有着明显的区别：它是非阻塞式服务器，而且速度相当快。得利于其非阻塞的方式和对epoll的运用，Tornado每秒可以处理数以千计的连接因此Tornado是实时Web服务的一个理想框架\n15.Django中哪里用到了线程？哪里用到了协程？哪里用到了进程？ 1.Django中耗时的任务用一个进程或者线程来执行，比如发邮件，使用celery.\n2.部署django项目是时候，配置文件中设置了进程和协程的相关配置。\n16.有用过Django REST framework吗？ Django REST framework是一个强大而灵活的Web API工具。使用RESTframework的理由有：\nWeb browsable API对开发者有极大的好处\n包括OAuth1a和OAuth2的认证策略\n支持ORM和非ORM数据资源的序列化\n全程自定义开发\u0026ndash;如果不想使用更加强大的功能，可仅仅使用常规的function-based views额外的文档和强大的社区支持\n17.对cookies与session的了解？他们能单独用吗？ Session采用的是在服务器端保持状态的方案，而Cookie采用的是在客户端保持状态的方案。但是禁用Cookie就不能得到Session。因为Session是用Session ID来确定当前对话所对应的服务器Session，而Session ID是通过Cookie来传递的，禁用Cookie相当于SessionID,也就得不到Session。\n爬虫 1.试列出至少三种目前流行的大型数据库 2.列举您使用过的Python网络爬虫所用到的网络数据包? requests, urllib,urllib2, httplib2\n3.爬取数据后使用哪个数据库存储数据的，为什么？ 4.你用过的爬虫框架或者模块有哪些？优缺点？ Python自带：urllib,urllib2\n第三方：requests\n框架： Scrapy\nurllib 和urllib2模块都做与请求URL相关的操作，但他们提供不同的功能。\nurllib2: urllib2.urlopen可以接受一个Request对象或者url,(在接受Request对象时，并以此可以来设置一个URL的headers),urllib.urlopen只接收一个url。\nurllib 有urlencode,urllib2没有，因此总是urllib, urllib2常会一起使用的原因\nscrapy是封装起来的框架，他包含了下载器，解析器，日志及异常处理，基于多线程，twisted的方式处理，对于固定单个网站的爬取开发，有优势，但是对于多网站爬取100个网站，并发及分布式处理不够灵活，不便调整与扩展\nrequests是一个HTTP库，它只是用来请求，它是一个强大的库，下载，解析全部自己处理，灵活性高\nScrapy优点：异步，xpath，强大的统计和log系统，支持不同url。shell方便独立调试。写middleware方便过滤。通过管道存入数据库\n5.写爬虫是用多进程好？还是多线程好？ 6.常见的反爬虫和应对方法？ 7.解析网页的解析器使用最多的是哪几个? 8.需要登录的网页，如何解决同时限制ip，cookie,session 9.验证码的解决? 10.使用最多的数据库，对他们的理解？ 11.编写过哪些爬虫中间件？ 12.“极验”滑动验证码如何破解？ 13.爬虫多久爬一次，爬下来的数据是怎么存储？ 14.cookie过期的处理问题？ 15.动态加载又对及时性要求很高怎么处理？ 16.HTTPS有什么优点和缺点？ 17.HTTPS是如何实现安全传输数据的？ 18.TTL，MSL，RTT各是什么？ 19.谈一谈你对Selenium和PhantomJS了解 20.平常怎么使用代理的 ？ 21.存放在数据库(redis、mysql等)。 22.怎么监控爬虫的状态? 23.描述下scrapy框架运行的机制？ 24.谈谈你对Scrapy的理解？ 25.怎么样让 scrapy 框架发送一个 post 请求（具体写出来） 26.怎么监控爬虫的状态 ？ 27.怎么判断网站是否更新？ 28.图片、视频爬取怎么绕过防盗连接 29.你爬出来的数据量大概有多大？大概多长时间爬一次？ 30.用什么数据库存爬下来的数据？部署是你做的吗？怎么部署？ 31.增量爬取 32.爬取下来的数据如何去重，说一下scrapy的具体的算法依据。 33.Scrapy的优缺点? 34.怎么设置爬取深度？ 35.scrapy和scrapy-redis有什么区别？为什么选择redis数据库？ 36.分布式爬虫主要解决什么问题？ 37.什么是分布式存储？ 38.你所知道的分布式爬虫方案有哪些？ 39.scrapy-redis，有做过其他的分布式爬虫吗？ 数据库 MySQL 1.主键 超键 候选键 外键 主键：数据库表中对存储数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值(Null).\n超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。\n候选键：是最小超键，即没有冗余元素的超键。\n外键：在一个表中存在的另一个表的主键称此表的外键。\n2.视图的作用，视图可以更改么？ 视图是虚拟的表，与包含数据的表不一样，视图只包含使用时动态检索数据的查询;不包含任何列或数据。使用视图可以简化复杂的sql操作，隐藏具体的细节，保护数据;视图创建后，可以使用与表相同的方式利用它们。\n视图不能被索引，也不能有关联的触发器或默认值，如果视图本身内有order by则对视图再次order by将被覆盖。\n创建视图： create view xxx as xxxxxx\n对于某些视图比如未使用联结子查询分组聚集函数Distinct Union等，是可以对其更新的，对视图的更新将对基表进行更新;但是视图主要用于简化检索，保护数据，并不用于更新，而且大部分视图都不可以更新。\n3.drop,delete与truncate的区别 drop直接删掉表，truncate删除表中数据，再插入时自增长id又从1开始，delete删除表中数据，可以加where字句。\n1.delete 语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。truncate table则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器，执行速度快。\n2.表和索引所占空间。当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，而delete操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。\n3.一般而言，drop\u0026gt;truncate\u0026gt;delete\n4.应用范围。truncate只能对table，delete可以是table和view\n5.truncate和delete只删除数据，而drop则删除整个表（结构和数据)\n6.truncate与不带where的delete:只删除数据，而不删除表的结构（定义）drop语句将删除表的结构被依赖的约束(constrain),触发器（trigger)索引(index);依赖于该表的存储过程/函数将被保留，但其状态会变为:invalid.\n4.索引的工作原理及其种类 数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询，更新数据库表中数据。索引的实现通常使用B树以其变种B+树。\n在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。\n为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间（因为索引也要随之变动）\n5.连接的种类 6.数据库优化的思路 7.存储过程与触发器的区别 8.悲观锁和乐观锁是什么？ 9.你常用的mysql引擎有哪些?各引擎间有什么区别? Redis 1.Redis宕机怎么解决? 宕机:服务器停止服务‘\n如果只有一台redis，肯定 会造成数据丢失，无法挽救\n多台redis或者是redis集群，宕机则需要分为在主从模式下区分来看：\nslave从redis宕机，配置主从复制的时候才配置从的redis，从的会从主的redis中读取主的redis的操作日志1，在redis中从库重新启动后会自动加入到主从架构中，自动完成同步数据;\n2, 如果从数据库实现了持久化，此时千万不要立马重启服务，否则可能会造成数据丢失，正确的操作如下：在slave数据上执行SLAVEOF ON ONE,来断开主从关系并把slave升级为主库，此时重新启动主数据库，执行SLAVEOF，把它设置为从库，连接到主的redis上面做主从复制，自动备份数据。\n以上过程很容易配置错误，可以使用redis提供的哨兵机制来简化上面的操作。简单的方法:redis的哨兵(sentinel)的功能\n2.redis和mecached的区别，以及使用场景 区别\n1、redis和Memcache都是将数据存放在内存中，都是内存数据库。不过memcache还可以用于缓存其他东西，例如图片，视频等等\n2、Redis不仅仅支持简单的k/v类型的数据，同时还提供list,set,hash等数据结构的存储\n3、虚拟内存-redis当物流内存用完时，可以将一些很久没用的value交换到磁盘\n4、过期策略-memcache在set时就指定，例如set key1 0 0 8，即永不过期。Redis可以通过例如expire设定，例如expire name 10\n5、分布式-设定memcache集群，利用magent做一主多从，redis可以做一主多从。都可以一主一丛\n6、存储数据安全-memcache挂掉后，数据没了，redis可以定期保存到磁盘(持久化)\n7、灾难恢复-memcache挂掉后，数据不可恢复，redis数据丢失后可以通过aof恢复\n8、Redis支持数据的备份，即master-slave模式的数据备份\n9、应用场景不一样，redis除了作为NoSQL数据库使用外，还能用做消息队列，数据堆栈和数据缓存等;Memcache适合于缓存SQL语句，数据集，用户临时性数据，延迟查询数据和session等\n使用场景\n1,如果有持久方面的需求或对数据类型和处理有要求的应该选择redis\n2,如果简单的key/value存储应该选择memcached.\n3.Redis集群方案该怎么做?都有哪些方案? 1,codis\n目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在节点数量改变情况下，旧节点数据客恢复到新hash节点\n2redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方介绍\n3.在业务代码层实现，起几个毫无关联的redis实例，在代码层，对key进行hash计算，然后去对应的redis实例操作数据。这种方式对hash层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的字典脚本恢复，实例的监控，等等\n4.Redis回收进程是如何工作的 一个客户端运行了新的命令，添加了新的数据。\nredis检查内存使用情况，如果大于maxmemory的限制，则根据设定好的策略进行回收。\n一个新的命令被执行等等，所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断回收回到边界以下。\n如果一个命令的结果导致大量内存被使用(例如很大的集合的交集保存到一个新的键)，不用多久内存限制就会被这个内存使用量超越。\nMongoDB 1.MongoDB中对多条记录做更新操作命令是什么？ 2.MongoDB如何才会拓展到多个shard里？ 测试 3.编写测试计划的目的是 4.对关键词触发模块进行测试 5.其他常用笔试题目网址汇总 6.测试人员在软件开发过程中的任务是什么 7.一条软件Bug记录都包含了哪些内容？ 8.简述黑盒测试和白盒测试的优缺点 9.请列出你所知道的软件测试种类，至少5项 10.Alpha测试与Beta测试的区别是什么？ 11.举例说明什么是Bug？一个bug report应包含什么关键字？ 大数据 1.找出1G的文件中高频词 2.一个大约有一万行的文本文件统计高频词 3.怎么在海量数据中找出重复次数最多的一个？ 4.判断数据是否在大量数据中 ","permalink":"https://yurooc.github.io/blog/python%E5%9F%BA%E7%A1%80/","summary":"Python基础 1.python新式类和经典类的区别？ a. 在python里凡是继承了object的类，都是新式类 b. Python3里只有新式类 c.","title":"Python基础面经"},{"content":"计算机网络篇 1.HTTP常见状态码 1xx: 接受，继续处理\n101：在HTTP升级为WebSocket的时候，如果服务器同意变更，就会发送状态码 101。\n103（Early Hints）：客户端应在服务端返回HTML前开始预加载资源\n200: 成功，并返回数据\n201: 已创建\n202: 已接受\n203: 成功，但未授权\n204: 成功，无内容\n205: 成功，重置内容\n206: 成功，部分内容，用来实现断点续传\n301: 永久重定向。场景是使用域名跳转，新的URL在响应中给出\n302: 临时重定向。场景是未登陆的用户跳转登录；浏览器默认使用get方式重新发出请求，会导致第一次以post请求的参数丢失；（才衍生出了307状态码）\n303: 临时重定向，强制浏览器将请求方法从POST改到GET；\n304: 资源未修改，可使用缓存（协商缓存）\n305: 需代理访问\n307: 307 和 302 一样是临时重定向，唯一的区别在于，307 状态码不允许浏览器将原本为 POST 的请求重定向到 GET 请求上。\n308: 308 和 301 一样是永久重定向，唯一的区别在于，308 状态码不允许浏览器将原本为 POST 的请求重定向到 GET 请求上。\n400: 请求语法错误\n401: 要求身份认证\n403: 拒绝请求\n404: 资源不存在\n405: 请求方法不允许\n500: 服务器错误\n502: 网关错误：服务器作为网关或代理出现错误\n503: 服务不可用：服务器目前无法使用\n504: 网关超时：网关或代理服务器，未及时获取请求\n详细说说 103 状态码 (Early Hints) 2022年 6月Chrome 官方宣布在 chrome 103 版本对 HTTP 103 状态码提供了支持；\nChrome 官方也宣布在 chrome 106 版本对 HTTP/2 Server Push进行禁用；\n正常情况下，我们需要等待 HTML 页面的返回后，才可以知道下一步需要去加载哪些 JS、CSS文件，这中间有一段的等待时间就被浪费掉了；这尤其在SSR项目中尤为明显； HTTP 103 状态码可以返回一个初步的 HTTP 响应，浏览器可以使用这些提示来预连接，并在等待资源响应的同时请求子资源。 它在 SSR 项目里面会非常有用；在SPA项目里面，大部分的逻辑都在客户端，HTML 很小，这时候我们只需要用常规的preload、preconnect之类的手段就可以了； 103 状态码和 HTTP2服务器推送 的区别 使用HTTP2服务器推送时，很多资源其实浏览器第一次请求就已经缓存下来了，但是服务端推送仍然会推送已缓存的资源，会导致网络带宽浪费；这是它的一个缺点，所以使用的人也较少；\nHTTP2服务器推送是直接发送资源，而103状态码只是向浏览器发送资源提示，浏览器可以控制是否需要这些资源，因为相同的资源可能已经在浏览器缓存过了； 总的来说，HTTP103 Early Hints 它能够解决网络带宽浪费的问题，可以说是 HTTP/2 Server Push 的升级版。不过目前还没有完全覆盖服务器推送的所有用例； 为什么需要 302 307 308 状态码 301: 永久重定向。场景是使用域名跳转，新的URL在响应中给出 302: 临时重定向。场景是未登陆的用户跳转登录；浏览器默认使用get方式重新发出请求，会导致第一次以post请求的参数丢失；（才衍生出了307状态码） 303: 临时重定向，强制浏览器将请求方法从POST改到GET； 307: 307 和 302 一样是临时重定向，唯一的区别在于，307 状态码不允许浏览器将原本为 POST 的请求重定向到 GET 请求上。 308: 308 和 301 一样是永久重定向，唯一的区别在于，308 状态码不允许浏览器将原本为 POST 的请求重定向到 GET 请求上。 2.从输入URL到呈现页面过程 这个流程可以分为两部分来说，第一部分是浏览器请求响应的过程；\n输入URL：用户在地址栏按下回车，先检查输入的是搜索关键字还是符合url的规则，然后将其组装成完整 URL进行访问； 检查缓存：然后会先检查本地强缓存是否可用，如果可用就直接从缓存中返回资源； DNS解析：如果强缓存不可用，就会进行DNS解析，通过递归查询和迭代查询解析域名来得到域名对应的IP地址； DNS查询的顺序为：浏览器IP缓存，操作系统IP缓存，Hosts文件，DNS根服务器； 建立TCP连接：得到IP地址后，会进行三次握手去建立TCP连接； 发送HTTP请求：建立TCP连接后发送 HTTP 请求，发送HTTP请求时会携带上cookie和缓存的标识字段； 负载均衡：服务端网关收到HTTP请求后，可能会有一系列的负载均衡处理，通过反向代理分配给对应集群中的服务器去执行； 服务器返回响应：服务器收到请求后，先根据请求头的缓存标识来判断缓存是否生效，生效就返回304状态码；不生效就返回资源和200状态码（在返回200的响应报文前，还可能会返回103的响应报文）； 浏览器接收HTTP响应：浏览器接受到HTTP响应后根据 connection:keep-alive 的值来选择通过 四次挥手来断开TCP连接，或者保留； 同时浏览器还会缓存响应头里的缓存标识字段； 到此为止，浏览器请求响应的过程就结束了；第二部分就是浏览器解析并渲染的过程；\n构建DOM树：浏览器从上到下解析 HTML 文档生成DOM节点树； 构建CSSOM树：浏览器解析遇到样式时，会进行异步下载，下载完成后构建 CSSOM树； 值得一提的是，当遇到不带async和defer的script时，会阻止解析HTML并进行下载和执行； 并且CSS和DOM渲染，JS和DOM解析之间是有阻塞关系的； 构建渲染树：根据DOM节点树和CSSOM树构建渲染树（Render）； 布局（Layout）：根据渲染树将DOM节点树每一个节点布局在屏幕上的正确位置； 绘制（Paint）：绘制所有节点，为每一个节点适用对应的样式，绘制到屏幕上； 绘制的过程中还有很多细节，包括说： 构建图层树：需要对布局树进行分层，生成图层树（比如说Z轴排序） 生成绘制列表：将图层的绘制拆分为很多的绘制指令，并按顺序组成绘制列表，并提交到合成线程中； 光栅化（栅格化）生成位图：合成线程将图层划分成图块，并在光栅化线程池中将图块转换成位图。 同时因为用户只能看到视口的这一部分，所以合成线程就会按照视口附近的图块来优先生成位图， 显示：一旦所有的图块都被光栅化，合成线程就会提交绘图指令给浏览器进程；浏览器进程生成页面并显示到屏幕上； 3.TCP、UDP TCP、UDP 的特点 TCP是一个面向连接的传输层协议。是可靠的、基于字节流的；TCP还具有超时重传、拥塞控制的机制； 而UDP是一个无连接的传输层协议。 面向连接指的是需要三次握手建立链接\n可靠性指 TCP 具有 确认应答ACK 和 序列号来实现可靠传输；\n基于字节流指的是：UDP的传输是将一个完整的用户消息发送一个UDP报文；而TCP是将一条用户消息根据滑动窗口的字节大小，拆分成多个TCP报文段（TCP将数据看作一连串字节流）\nTCP 和 UDP 的区别 TCP 是面向连接的，UDP 是无连接的即发送数据前不需要先建立链接 TCP 是可靠传输，保证数据正确且有序；UDP是不可靠的，可能丢包或乱序 TCP 是面向字节流，UDP 面向报文，并且网络出现拥塞不会使得发送速率降低 TCP 首部开销大，最小20字节最大60字节，而 UDP 首部开销小，仅8字节 TCP 只能是 1 对 1 的，UDP 支持 1 对 1,1 对多； HTTP 和 TCP 的不同 HTTP的责任是去定义数据，在两台计算机相互传递信息时，HTTP规定了每段数据以什么形式表达才是能够被另外一台计算机理解。 而TCP所要规定的是数据应该怎么传输才能稳定且高效 TCP 的可靠性 序列号：TCP给每一个包一个序号，保证接收端的按序接受； 确认应答ACK：接收端收到包就会回一个相应的确认ACK，如果发送端在一个往返时延内未收到确认就会重传； 流量控制：通过控制发送者的发送速度来缓解接收者的拥塞； 拥塞控制：当网络出现拥塞的时候，TCP能够减小向网络注入数据的速率和数量，缓解拥塞； 流量控制 和 拥塞控制 的区别 流量控制 是作用于接收者的，它是控制发送者的发送速度从而使接收者来得及接收，防止丢失数据包的。 拥塞控制 是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况 流量控制机制 \u0026amp; 滑动窗口 对于发送端和接收端来说，TCP需要将发送的数据放到发送缓冲区，接收的数据放到接收缓冲区； 而流量控制的目的，就是为了提供一种机制：让发送端可以根据接收端的实际接受能力控制发送的数据量； TCP通过滑动窗口实现流量控制的机制，而滑动窗口大小是通过TCP首部的窗口大小字段来通知对方； TCP协议的头部信息中，有一个16位字段的窗口大小，窗口大小的内容就是接收端接收数据缓冲区的剩余大小；当接收端缓冲区面临溢出时，就会设置成一个更小值取告诉发送端要控制发送的数据量；发送端收到后就会对数据发送量进行调整，形成完整的流量控制； 拥塞控制机制 体现在四个方面\n慢启动：开始的时候不要发送大量数据，先测试一下网络，然后慢慢由小到大的增加拥塞窗口大小；直到达到慢启动阈值； 拥塞避免：一旦判断网络出现拥塞，就将慢启动阈值设置为出现拥塞时一半的大小，并把拥塞窗口设为1，再重新开始慢启动算法 快速重传：就是接收方在收到一个失序的报文后立即发出重复确认，快重传算法规定发送方只要连续收到三个重复确认就立即重传对方尚未收到的报文段，而不用继续等重传计时器到期； 快速恢复：当发送方连续收到三个重复确认时，就不执行慢启动算法而是执行拥塞避免算法； 拥塞窗口 是指发送端还可以传输的数据量大小，上文提到有通过流量控制机制来限制发送窗口的大小，而最终会取两者之间的较小值；\n三次握手 TCP 三次握手流程 第一步：客户端发送SYN报文到服务端发起握手 第二步：服务端收到SYN报文之后回复SYN和ACK报文给客户端 第三步：客户端收到SYN和ACK，向服务端发送一个ACK报文 TCP 快速打开（TFO） TFO 就是为了减少三次握手带来的延时，\n在 TFO 的流程中，首轮三次握手服务端会计算得到一个 TFO cookie，放到 TCP 报文的 Fast Open里面 客户端拿到这个 cookie 后缓存下来，并完成正常的三次握手； 下一次的三次握手，客户端就会将之前的 cookie 和 HTTP请求、SYN 发给服务端 服务端验证 cookie 是否合法，如果合法就正常返回 SYN+ACK；并且返回HTTP响应； 最后完成三次握手的剩余流程； 三次握手的意义 客户端和服务端都需要直到各自可收发，因此需要三次握手\n第一次握手成功让服务端知道了客户端具有发送能力 第二次握手成功让客户端知道了服务端具有接收和发送能力，但此时服务端并不知道客户端是否接收到了自己发送的消息（如果服务端这时立刻给客户端发送数据，这个时候客户端可能还没有准备好接收数据） 第三次握手让服务端知道了客户端做好了接收自己发送的消息的准备 为什么 TCP 建立连接需要三次握手，而不是两次 因为这是为了防止出现失效的连接请求报文段被服务端接收的情况，从而产生错误。 三次握手过程中可以携带数据吗 第一次、第二次握手不可以携带数据，因为一握二握时还没有建立连接，会让服务器容易受到攻击（只需要在第一次握手的报文里放大量数据，服务器就会消耗更大的时间和内存空间去处理数据） 而第三次握手，此时客户端已经处于 (已建立连接状态) ，对于客户端来说，已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也是没问题的。 四次挥手 为什么要四次挥手 \u0026amp; 四次挥手流程 因为TCP是全双工通信，不能单方面完全断开连接\n第一次挥手，客户端发送FIN给服务端 第二次挥手，服务端回复ACK给客户端，服务端还可以继续向客户端发送数据（若数据没有发送完） 第三次挥手，服务端发送FIN给客户端 第四次挥手，客户端回复ACK给服务端，客户端经过 2MSL 的时间后断开，服务端接收到了客户端发出的ACK后立刻断开了到客户端的连接 至此TCP连接才完全断开。\n四次挥手结束等待 2MSL 的意义 虽然按道理，四个报文都发送完毕，就可以立即断开，但是我们必须假设网络是不可靠的，有可以最后一个ACK丢失。 如果最后一个 ACK 丢失了，那么服务端没有收到 ACK 就会发起重传；再次发送 FIN 给客户端； 客户端收到重传的 FIN 后，会重发 ACK 并重新等待 2MSL 的时间来确保服务端收到了自己的 ACK； 总结：\n1 个 MSL 确保第四次挥手中主动关闭方最后的 ACK 报文最终能达到对端 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达 4.HTTP HTTP 是超文本传输协议，HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。\nHTTP 的特点 特点：无连接、无状态、灵活\n无连接：每一次请求都要连接一次，请求结束就会断掉，不会保持连接（HTTP1.1后可以保持连接长连）； 无状态：每一次请求都是独立的，请求结束不会记录连接的任何信息，减少了网络开销，这是优点也是缺点 灵活：通过http协议中头部的Content-Type标记，可以传输任意数据类型的数据对象(文本、图片、视频等等)，非常灵活 缺点：无状态、不安全、明文传输、队头阻塞\n无状态：请求不会记录任何连接信息，就无法区分多个请求发起者身份是不是同一个客户端的； 不安全：明文传输可能被窃听，缺少身份认证也可能遭遇伪装，还有缺少报文完整性验证可能遭到篡改 明文传输：报文(header部分)使用的是明文，直接将信息暴露给了外界，WIFI陷阱就是复用明文传输的特点，诱导你连上热点，然后疯狂抓取你的流量，从而拿到你的敏感信息 队头阻塞：开启长连接(下面有讲)时，只建立一个TCP连接，同一时刻只能处理一个请求，那么当请求耗时过长时，其他请求就只能阻塞状态(如何解决下面有讲) HTTP 报文组成 http报文：由请求报文和响应报文组成\n请求报文：由请求行、请求头、空行、请求体四部分组成\n响应报文：由状态行、响应头、空行、响应体四部分组成\n请求行：包括请求的方法，路径和协议版本 请求头/响应头：包含了请求的一些附加的信息，一般是以键值的形式成对存在 空行：协议中规定请求头和请求主体间必须用一个空行隔开，用来区分首部与实体，因为请求头都是key:value的格式，当解析遇到空行时，服务端就知道下一个不再是请求头部分，就该当作请求体来解析了； 请求体：对于post请求，所需要的参数都不会放在url中，这时候就需要一个载体了，这个载体就是请求主体 状态行：包含http协议及版本、数字状态码、状态码英文名称 响应体：服务端返回的数据 HTTP 的请求方法 HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法\nHTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT\nhttp/1.1规定了以下请求方法(注意，都是大写):\nGET： 请求获取Request-URI所标识的资源\nPOST： 一般用于修改Request-URI的资源\nHEAD： 请求获取由Request-URI所标识的资源的响应消息报头\nPUT： 请求服务器存储一个资源\nDELETE： 请求服务器删除对应所标识的资源\nTRACE： 请求服务器回送收到的请求信息，主要用于测试或诊断\nCONNECT： 建立连接隧道，用于代理服务器\nOPTIONS： CORS跨域请求的预检请求；\nGET 和 POST的区别 从Restful语义来看：GET用来无副作用的请求资源，理应幂等，POST用来新资源； 从参数角度来看：GET请求一般放在URL中，POST请求放在请求体中，看起来post比get安全，但是在抓包的情况下都是一样的（所以面试的时候别再说POST比GET安全了）。 从编码角度看：GET只能进行 url 编码，参数的数据类型只接受ASCII字符，而POST支持更多的编码类型且不对数据类型限制。 从回退角度来看：GET在浏览器回退时是无害的，而POST会再次发起请求 从记录角度来看：GET请求参数会被完整保留在浏览器的历史记录里，而POST中的参数不会被保留 从发送角度来看：GET请求会一次性发送请求报文，POST请求通常分为两个TCP数据包，首先发 header 部分，如果服务器响应 100， 然后发 body 部分。 是什么限制了GET方法的URL长度 从HTTP协议规范层面说，规范没有对URL的长度进行限制，是浏览器、代理服务器的读取有限制；\nPOST方法真的不能被缓存吗 默认情况下，post不会被缓存，但是如果我们有中间代理服务器（Node），也是可以实现缓存的；\nHTTP 1.0 http1.0只支持POST/GET/HEAD命令 不支持断点续传，也就是说，每次都会传送全部的页面和数据。 只使用 header 中的Last-Modified、If-Modified-Since（协商缓存） 和 Expires（强缓存） 作为缓存失效的标准。 HTTP 1.1 引入了持久连接，即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive； 引入了管道机制，即在同一个TCP连接里，客户端不用等待请求响应就可以发送多个请求，但要求服务端要按发送顺序返回； 支持断点续传，通过使用请求头中的 Range 来实现（206状态码）。 HTTP 1.1 中新增加了 E-tag、If-None-Match、Cache-Control 等缓存控制标头来控制缓存失效。 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。 新增方法：PUT、 OPTIONS、 DELETE等。 更多的缓存标识：Cache-Control、ETag、If-None-Match 缺点：\n由于队头阻塞带来的高延迟 巨大的http头部 不支持服务器推送消息 HTTP 2.0 二进制分帧：在之前的 HTTP 版本中，我们是通过文本的方式传输数据。在 HTTP/2 中信息和数据体都是二进制，并且统称为\u0026quot;帧\u0026quot;：用头信息帧放头部字段，用数据帧放请求数据体，是一堆乱序的二进制帧，它们不存在先后关系，因此不需要排队等待，是HTTP2多路复用的基础。 头部压缩 HTTP2使用 HPACK算法 压缩头部然后再发送，并在两端维护了索引表，用于记录出现过的 header，后面在传输过程中就可以传输已经记录过的 header 的键名，对端收到数据后就可以通过键名找到对应的值。 多路复用 在一个连接里，可以同时发送多个请求或回应，且不用按顺序一一对应，这样子解决了HTTP队头阻塞的问题。 服务器推送允许浏览器发送一个请求后，服务器主动向浏览器推送与这个请求相关的资源，这样浏览器就不用发起后续请求去获取一些资源。但是Chrome106版本禁用了，改为103状态码； 服务器推送时，客户端的特点： 客户端可以缓存推送的资源 客户端可以拒收推送过来的资源 服务器可以按照优先级推送资源 HTTP 3.0 Google搞了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP/3 上\nHTTP3 出现原因 \u0026amp; HTTP2 缺点 底层协议还是TCP，仍然需要三次握手来确认连接成功， TCP的队头阻塞并没有彻底解决，在 HTTP2 中，多个请求是跑在一个TCP连接中的。但当HTTP/2出现丢包时，整个 TCP 都要开始等待重传，那么就会阻塞该TCP连接中的所有请求。 QUIC 实现了快速握手功能。由于QUIC是基于UDP的，不需要三次握手，这意味着QUIC可以用最快的速度来发送和接收数据。 3RTT =\u0026gt; 0/1 RTT；根据是否要TLS加密 实现了类似TCP的可靠传输，虽然UDP不提供可靠性的传输，但QUIC在UDP的基础之上增加了一层来保证数据可靠性传输。 用的ACK模式，只是QUIC中包丢了就丢了，会重传一个新序号的包，通过包内的offset字段来确定这个包的位置； 集成了 TLS 加密功能，目前QUIC使用的是TLS1.3，相较于早期版本TLS1.3有更多的优点，其中最重要的一点是减少了握手所花费的RTT个数。 同样也提供了拥塞控制机制，包括慢启动、拥塞避免等； 也实现了多路复用，每个请求会在 quic 层面定义为一个 stream，丢包也只影响当前stream；彻底解决 TCP 中队头阻塞的问题（详细可阅读下文） 队头阻塞问题 队头阻塞是指当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞\nTCP 队头阻塞 TCP是可靠传输协议，当前一个数据丢失时，后面到的数据将在接收端等待到前一个丢失的数据被发送端重传并到达接收端为止 这种机制保证了数据的有序正确，但也有可能造成 TCP队头阻塞； HTTP 队头阻塞 HTTP1.1 允许在持久连接上可选的使用请求管道 管道允许客户端在已发送请求后就发送下一个请求，不需要等待前一个请求响应，借此来减少等待时间； 但是客户端要求服务端按照请求发送的顺序返回响应，原因很简单：HTTP请求和响应并没有序列号标识，无法将乱序的响应与请求关联起来； 也就意味着如果一个响应返回延迟了，那么后续的响应都会延迟；这就造成了 HTTP队头阻塞； 解决方法 TCP队头阻塞问题是 TCP 自身的机制决定的，无法避免，所以 google 才推出 QUIC协议，也就是所谓的 HTTP3； HTTP2使用帧和流来传输数据，因为流的概念是虚拟的，所以HTTP2可以在一个TCP连接上用流同时发送多个帧，也就是所谓的多路复用：多个请求都复用一个连接来处理； 在流的层面上看，同个流的帧是严格有序的，而从连接的层面上看，传输的都是乱序的帧；多个请求、响应之间没有的顺序关系；也就不需要排队等待，避免了队头阻塞的问题； 简单来说：就是HTTP2通过帧、流、多路复用的方式，让请求和响应不用按顺序一一对应，解决队头阻塞的问题； 对于 HTTP1来说，可以使用 并发连接 和 域名分片 来一定程度上解决问题，chrome对单域名 限制并发6个TCP持久连接；而域名分片我们可以在一个域名下分出多个二级域名，而它们最终指向同一个服务器，这样可以并发的数量就更多； 总结 HTTP/1.1有两个主要的缺点：安全不足和性能不高。 HTTP/2完全兼容HTTP/1，头部压缩、多路复用等技术可以充分利用带宽，降低延迟，从而大幅度提高上网体验； QUIC 是 HTTP/3 中的底层支撑协议，该协议基于 UDP，又取了 TCP 中的精华，实现了即快又可靠的协议。 5.HTTPS 实际上， HTTPS 并不是一个新的协议，它只是在 HTTP 和 TCP 的传输中建立了一个安全层，它其实就是 HTTP + SSL/TLS 协议组合而成，而安全性的保证正是 SSL/TLS 所做的工作。\nHTTPS 的优缺点 优点\n使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器 HTTPS 协议是可进行加密传输、身份认证的网络协议，要比 http 协议安全 HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本（除非用户主动信任了伪造证书） 缺点\n证书费用以及更新维护。 https 加密解密需要消耗更多服务器资源； https 握手阶段比较费时， HTTPS 和 HTTP 区别 HTTP 是明文传输，HTTPS 协议是可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。 HTTPS对搜索引擎更友好，利于 SEO；谷歌、百度优先索引 HTTPS 网页。 HTTPS 标准端口 443，HTTP 标准端口 80。 HTTPS 需要用到SSL证书，而 HTTP 不用。 HTTPS 握手 握手过程 客户端发起 HTTPS 请求，发送客户端生成的随机数和支持的加密算法列表； 服务端返回证书、服务端生成的随机数、选择的加密方法给客户端； 客户端对证书进行合法性验证，验证通过后再生成一个随机数 客户端通过证书中的公钥对随机数进行加密传输到服务端，服务端接收后通过私钥解密得到随机数 三次握手此时已经完成，之后客户端和服务端都会根据这三个随机数，生成一个随机对称密钥，之后的数据都通过随机对称密钥进行加密传输。 客户端如何验证证书的合法性 首先浏览器读取证书中的证书所有者、有效期等信息进行一一校验。 浏览器接着判断证书中的颁发者CA是否受信任，用以校验证书是否为合法机构颁发； 如果证书不可信，浏览器就会提示证书不可信。 如果证书可信，那么浏览器就会用 CA机构 的公钥对证书里面的签名进行解密，得到hash值和加密算法。 再用证书里提到的加密算法，将证书的明文内容加密成另一个hash值，对比两个hash值是否相同；相同则证明服务器发来的证书合法，没有被篡改。 再比对一下证书中的域名和当前请求的域名是否一致，以确保证书不会被掉包。 此时浏览器就可以读取证书中的公钥，用于后续加密了。 为什么需要三个 随机数 因为随机数是伪随机的，三个伪随机数就十分随机了\n6.DNS DNS 的作用 DNS 的作用就是通过域名查询到具体的 IP。是应用层协议，通常该协议运行在UDP协议之上，使用的是53端口号。\nDNS 查询流程 以 Chrome 为例，当你在浏览器中想访问 www.google.com 时，会通过进行以下操作：\nChrome 先查看浏览器自身有没有该域名的 IP 缓存 Chrome 再查看操作系统有没有该域名的 IP 缓存 Chrome 再查看 Host 文件有没有该域名的解析配置 如果在hosts文件中也没有找到对应的条目，浏览器就会请求本地域名服务器localDNS（LDNS）来解析这个域名。（这是递归查询的流程）\n如果 LDNS 也没有该域名的记录，就会进行迭代查询： LDNS 先去 DNS根域名服务器查询，这一步查询会找出负责 com 这个一级域名的服务器 LDNS 再去该服务器查询 google.com 这个二级域名 LDNS 再去查询 www.google.com 这个三级域名的地址 LDNS 返回给浏览器，并缓存起来 递归查询 和 迭代查询 递归查询指的是查询请求发出后，域名服务器代为向下一级域名服务器发出请求，最后向用户返回查询的最终结果。使用递归查询，用户只需要发出一次查询请求。 迭代查询指的是查询请求后，域名服务器返回单次查询的结果。下一级的查询由用户自己请求。使用迭代查询，用户需要发出 多次的查询请求。 所以一般而言，本地DNS服务器查询是递归查询，而本地DNS服务器向其他域名服务器请求的过程是迭代查询的过程\n在客户端查找DNS缓存也就是递归查询；\n去查找服务端的就是迭代查询\nDNS 实现负载平衡 某些大型网站一般都会使用多台服务器提供服务，因此一个域名可能对应多个服务器地址； 当用户发起网站域名的 DNS 请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合 在每个响应中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求。 以此将用户的请求均衡的分配到各个不同的服务器上，这样来实现负载均衡。 还有一种负载均衡的方式，使用反向代理，用户的请求都发送到反向代理服务上，然后由反向代理服务器来转发请求到真实的服务器上，以此来实现集群的负载平衡。\nDNS 为什么选择 UDP 协议作为传输层协议 为了得到一个域名的 IP 地址，往往会向多个域名服务器查询，而TCP协议存在三次握手，会造成DNS服务变得很慢\n7.计算机网络模型 OSI、TCP/IP、5层模型 各层基本作用 应用层：为应用程序提供网络服务； 表示层：数据格式化、加密、解密； 会话层：建立、维护、管理会话连接； 传输层：建立、维护、管理到端连接； 网络层：IP寻址和路由选择； 数据链路层：控制网络层与物理层之间通信； 物理层：通过光缆、无线电波等方式连接组网；传输比特流0和1； 网络层 IP寻址 和 路由 寻址就是根据IP地址找到具体的设备。 因为IPv4的网络是一个树状模型，顶层网络下方有多个子网，子网下方还有子网，最后才是设备；IP协议的寻址过程就是要逐级找到网络，最后定位设备； 路由就是选择数据传输的线路 在寻址过程中，数据总是存在于某个局域网中。如果目的地在局域网中，就可以直接定位到设备了；但是如果目的地不在局域网中，这个时候就需要再去往其它网络。 由于网络和网络之间是网关在链接，所以如果目的地IP不在局域网中，就要为IP封包选择通往下一个网络的路径，也就是选择其中一个网关； 当包去往下一个节点后，就进入了新的路由节点，然后就继续上述过程，直到最终定位到设备； 网络层就是通过IP寻址找到最终的设备，又要借助路由在每个节点选择数据传输的线路，所以路由和寻址是相辅相成的关系；\n8.WebSocket WebSocket 是 Html5 定义的一个新协议，出现的目的是即时通讯，替代轮询 与传统的 http 协议不同，它实现了浏览器与服务器全双工通信。 HTTP 与 WebSocket 相同点： 都是一样基于TCP的应用层协议，都是可靠性传输协议。 不同点： WebSocket 是全双工通信协议，通信双方可以实时且同时发送和接收消息。而HTTP是单向的； WebSocket 没有了 Request 和 Response 的概念 WebSocket 需要依赖 HTTP 协议进行一次握手。握手成功过后数据就直接从 TCP 通道传输，与 HTTP 无关； WebSocket 数据格式比较轻量，它的据包头部较小，而HTTP协议每次通信都需要携带完整的头部 WebSocket 无跨域问题 WebSocket 握手协议 与 Http握手 的区别 WebSocket 的握手协议相比 Http原本的握手协议 ，多了两个属性：\nUpgrade:webSocket Connection:Upgrade 客户端发送的握手协议，带有两个额外的属性，服务端就会返回101状态码，客户端收到101状态码后就成功\nWebSocket 心跳 可能会有某些未知情况导致 socket 断开，而客户端和服务端却不知道，需要客户端定时发送一个 心跳 ping 让服务端知道自己在线\n服务端也需要回答一个 心跳 pong 告诉客户端自己可用，否则视为断开。\nWebSocket 状态 WebSocket 对象中的 readyState 属性有四种状态：\n0：表示正在连接 1：表示连接成功，可以通信了 2：表示连接正在关闭 3：表示连接已经关闭，或者打开连接失败 Websocket 和 socket 的区别 Socket是应用层与TCP/IP协议通信的中间软件抽象层，它是一组接口。 而WebSocket则不同，它是一个完整的应用层协议，包含一套标准的API。 9.即时通信方案 即时通信方案，也就是指两个客户机能够同时的收发消息；\n方案选择 短轮询：前端用定时器每隔一段时间就ajax向后端获取更新； 长轮询：长轮询是短轮询的改进，请求到服务端后会被挂起，直到有新的消息才会返回响应；然后再重新发起请求； 基于流：基于流的推送技术就是指 SSE；SSE是一个H5的属性，它只能由服务器向浏览器发送数据，所以协作式通过 http 发送消息，sse 接受消息； Websocket：WebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通信的协议；钉钉表格就是用的原生WebSocket； Socket.io：其实 Socket.IO 只是为了解决 websocket 的兼容性的一个解决方案，因为websocket出现的较新，所以一些老的浏览器兼容性不好，而 Socket.IO就是将websocket、长轮询两种通信方式封装成了统一的通信接口进行降级兼容； 单工、半双工和全双工通信 单工通信是指消息只能单方向传输的工作方式，数据信息从一端到另一端是单方向的。例：广播。\n半双工通信可以实现双向的通信，但是不能在两个方向同时进行，必须交替进行。这中模式下，接收端和发送端可以互相转换。例：对讲机。\n全双工通信是指在通信的任意时刻，都允许数据同时在两个方向上传输，在这个模式下，通信系统的每一端都设置了发送器和接收器\n","permalink":"https://yurooc.github.io/blog/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E7%BB%8F/","summary":"计算机网络篇 1.HTTP常见状态码 1xx: 接受，继续处理 101：在HTTP升级为WebSocket的时候，如果服务器同意变更，就会发送状态码 101","title":"计算机网络面经"},{"content":"Git 1.基本配置 1.1 设置用户信息\ngit config --global user.name \u0026#34;yurooc\u0026#34;\rgit config --global user.email \u0026#34;yurooc@163.com\u0026#34; 1.2 查看用户信息\ngit config --global user.name\rgit config --global user.eamil 2.获取本地仓库 创建一个空文件夹 cd进入文件夹中执行git init命令 本地仓库就创建成功了 2.1 基础操作命令 2.1.1\ngit add\t(工作区\u0026ndash;\u0026gt;暂存区) git commit (暂存区\u0026ndash;\u0026gt;本地仓库) 2.1.2 查看修改的状态(status)\n作用：查看修改的状态（暂存区、工作区） 命令：git status 2.1.3 添加工作区到暂存区（add）\ngit add 单个文件名|.可以添加单个文件名也可以用.表示所有文件\n2.1.4 提交暂存区到本地仓库(commit)\n将暂存区内容提交到本地仓库的当前分支\ngit commit -m \u0026quot;注释内容\u0026quot;\n2.1.5 查看提交日志(log)\n查看谁在什么时间修改或者提交了哪些文件\ngit log 或者git log [option]\n[option]:\n--all 显示所有分支 --pretty=oneline 将提交信息显示为一行 --abbrev-commit 使得输出的commit更简短 --graph 以图的形式显示 2.1.6 版本回退\n作用：切换版本\n命令：git reset --hard [commitID]\ncommitID可以用git log查看\n如何查看已经删除的记录：\ngit reflog\n这个指令可以看到已经删除的提交记录\n2.1.7 添加文件至忽略列表\n有些文件不需要git管理的时候，就可以在工作区创建一个.gitignore文件，在里面列出来要忽略的文件的格式\n3.分支 3.1 查看本地分支\ngit branch\n3.2 创建本地分支\ngit branch 分支名\n3.3 切换分支(checkout)\ngit checkout 分支名\n我们还可以直接切换到一个不存在的分支(创建并切换)：\ngit cheackout -b 分支名\n3.4 合并分支(merge)\n一个分支上的提交可以合并到另一个分支\ngit merge 分支名称\n3.5 删除分支\n不能删除当前分支，只能删除其他分支\ngit branch -d b1 删除分支时，需要做各种检查\ngit branch -D b1不做任何检查，强制删除\n4.操作远程仓库 4.1 添加远程仓库\n此操作是与远程库进行链接\ngit remote add \u0026lt;远端名称\u0026gt; \u0026lt;仓库路径\u0026gt;\n远端名称：默认为origin，取决于远端服务器设置 仓库路径：从远端服务器获取url 4.2 查看远程仓库\ngit remote\n4.3 推送到远程仓库\ngit push [-f][--set-upstream][远端名称[本地分支名][:远端分支名]]\n如果远程分支名和本地分支名称相同，则可以只写本地分支 git push origin main --set-upstream推送到远端的同时并且建立起和远端分支的关联联系 git push --set-upstream origin main 如果当前分支已经和远端分支关联，则可以省略分支名和远端名 git push 将main分支推送到已关联的远端分支 4.4 查看本地分支和远程分支的关联关系\ngit branch -vv\n4.5 从远程仓库克隆\ngit clon \u0026lt;仓库路径url\u0026gt;[本地目录]\n本地目录可以省略，会自动生成一个目录\n4.6 从远程仓库中抓取和拉取\n远程分支和本地的分支一样，我们可以进行merge操作，只是需要先把远端仓库里的更新都下载到本地，再进行操作。\n抓取命令：git fetch [remote name][branch name]\tremote name 一般指origin 抓取指令就是将仓库里的更新都抓取到本地，不会进行合并 如果不指定远端名称和分支名，则抓取所有分支。 拉取命令：git pull [remote name][branch name] remote name 一般指origin 拉取命令就是将远端仓库的修改拉到本地并自动进行合并，等同于fetch+merge 如果不指定远端名称和分支名，则抓取所有并更新当前分支 ","permalink":"https://yurooc.github.io/blog/git/","summary":"Git 1.基本配置 1.1 设置用户信息 git config --global user.name \u0026#34;yurooc\u0026#34; git config --global user.email \u0026#34;yurooc@163.com\u0026#34; 1.2 查看用户信息 git config --global user.name git config --global user.eamil 2.获取本地仓库 创建一个空文件夹 cd进入文件夹中执行git in","title":"Git基本命令"},{"content":"你是1还是0？\n你是是还是否？\n你是要采取行动还是要无所作为？\n生活就是二进制\n每个决定都是由1或是0构成\n你要么采取行动，要么就什么都不做\n","permalink":"https://yurooc.github.io/about/","summary":"你是1还是0？ 你是是还是否？ 你是要采取行动还是要无所作为？ 生活就是二进制 每个决定都是由1或是0构成 你要么采取行动，要么就什么都不做","title":"Hello"},{"content":"一.Hugo中添加不蒜子计数 Hugo添加不蒜子页面浏览次数与阅读数据统计\n什么是不蒜子？\nBusuanzi是一个用于统计网站访问量的工具。它通常嵌入到网页中，可以追踪页面的浏览次数，方可数量积极其他一些基本的访问数据。这个工具可以帮助网站管理员了解他们的网站受欢迎程度和流量情况。\n使用步骤\n在head.html，footer.html，single.html，config.yml进行修改\n1.head.html\n我的papermod的路径为themes/PaperMod/layouts/partials/head.html\n添加以下代码\n\u0026lt;!-- busuanzi --\u0026gt; {{- if .Site.Params.busuanzi.enable -}} \u0026lt;script async src=\u0026#34;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;meta name=\u0026#34;referrer\u0026#34; content=\u0026#34;no-referrer-when-downgrade\u0026#34;\u0026gt; {{- end -}} 2.footer.html\n用于在站点底部显示总访问量与访客数\n我的PaperMod路径为themes/PaperMod/layouts/partials/footer.html\n添加以下代码，注意添加在\u0026lt;footer\u0026gt;代码块里\n\u0026lt;!-- busuanzi --\u0026gt; {{ if .Site.Params.busuanzi.enable -}} \u0026lt;div class=\u0026#34;busuanzi-footer\u0026#34;\u0026gt; \u0026lt;span id=\u0026#34;busuanzi_container_site_pv\u0026#34;\u0026gt; 本站总访问量\u0026lt;span id=\u0026#34;busuanzi_value_site_pv\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;次 \u0026lt;/span\u0026gt; \u0026lt;span id=\u0026#34;busuanzi_container_site_uv\u0026#34;\u0026gt; 本站访客数\u0026lt;span id=\u0026#34;busuanzi_value_site_uv\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;人次 \u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; {{- end -}} 3.single.html\n用于显示每篇文章阅读量\n我的papermod路径为themes/PaperMod/layouts/_default/single.html\n添加以下代码，加在\u0026lt;header\u0026gt;代码块内\n\u0026lt;!-- busuanzi --\u0026gt; {{ if .Site.Params.busuanzi.enable -}} \u0026lt;div class=\u0026#34;meta-item\u0026#34;\u0026gt;\u0026amp;nbsp·\u0026amp;nbsp \u0026lt;span id=\u0026#34;busuanzi_container_page_pv\u0026#34;\u0026gt;本文阅读量\u0026lt;span id=\u0026#34;busuanzi_value_page_pv\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;次\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; {{- end }} 4.config.yml\n回到根目录的config.yml，在params里加上busuanzi:功能\n显示统计即为true\nparams: busuanzi: enable: true 二.搜索功能 分别在中英文的文件夹下创建search.md（hugo new search.md），修改文件头为：\ntitle: \u0026#34;Search\u0026#34; date: ... draft: false layout: search config.yml中添加：\nmenu: main: -identifier: Search name: Search url: search weight: ... 三.目录栏放在左侧 1.首先找到目录 layouts/partials/toc.html，把之前的代码换成如下代码\n{{- $headers := findRE \u0026#34;\u0026lt;h[1-6].*?\u0026gt;(.|\\n])+?\u0026lt;/h[1-6]\u0026gt;\u0026#34; .Content -}} {{- $has_headers := ge (len $headers) 1 -}} {{- if $has_headers -}} \u0026lt;aside id=\u0026#34;toc-container\u0026#34; class=\u0026#34;toc-container wide\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;toc\u0026#34;\u0026gt; \u0026lt;details {{if (.Param \u0026#34;TocOpen\u0026#34;) }} open{{ end }}\u0026gt; \u0026lt;summary accesskey=\u0026#34;c\u0026#34; title=\u0026#34;(Alt + C)\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;details\u0026#34;\u0026gt;{{- i18n \u0026#34;toc\u0026#34; | default \u0026#34;Table of Contents\u0026#34; }}\u0026lt;/span\u0026gt; \u0026lt;/summary\u0026gt; \u0026lt;div class=\u0026#34;inner\u0026#34;\u0026gt; {{- $largest := 6 -}} {{- range $headers -}} {{- $headerLevel := index (findRE \u0026#34;[1-6]\u0026#34; . 1) 0 -}} {{- $headerLevel := len (seq $headerLevel) -}} {{- if lt $headerLevel $largest -}} {{- $largest = $headerLevel -}} {{- end -}} {{- end -}} {{- $firstHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers 0) 1) 0)) -}} {{- $.Scratch.Set \u0026#34;bareul\u0026#34; slice -}} \u0026lt;ul\u0026gt; {{- range seq (sub $firstHeaderLevel $largest) -}} \u0026lt;ul\u0026gt; {{- $.Scratch.Add \u0026#34;bareul\u0026#34; (sub (add $largest .) 1) -}} {{- end -}} {{- range $i, $header := $headers -}} {{- $headerLevel := index (findRE \u0026#34;[1-6]\u0026#34; . 1) 0 -}} {{- $headerLevel := len (seq $headerLevel) -}} {{/* get id=\u0026#34;xyz\u0026#34; */}} {{- $id := index (findRE \u0026#34;(id=\\\u0026#34;(.*?)\\\u0026#34;)\u0026#34; $header 9) 0 }} {{- /* strip id=\u0026#34;\u0026#34; to leave xyz, no way to get regex capturing groups in hugo */ -}} {{- $cleanedID := replace (replace $id \u0026#34;id=\\\u0026#34;\u0026#34; \u0026#34;\u0026#34;) \u0026#34;\\\u0026#34;\u0026#34; \u0026#34;\u0026#34; }} {{- $header := replaceRE \u0026#34;\u0026lt;h[1-6].*?\u0026gt;((.|\\n])+?)\u0026lt;/h[1-6]\u0026gt;\u0026#34; \u0026#34;$1\u0026#34; $header -}} {{- if ne $i 0 -}} {{- $prevHeaderLevel := index (findRE \u0026#34;[1-6]\u0026#34; (index $headers (sub $i 1)) 1) 0 -}} {{- $prevHeaderLevel := len (seq $prevHeaderLevel) -}} {{- if gt $headerLevel $prevHeaderLevel -}} {{- range seq $prevHeaderLevel (sub $headerLevel 1) -}} \u0026lt;ul\u0026gt; {{/* the first should not be recorded */}} {{- if ne $prevHeaderLevel . -}} {{- $.Scratch.Add \u0026#34;bareul\u0026#34; . -}} {{- end -}} {{- end -}} {{- else -}} \u0026lt;/li\u0026gt; {{- if lt $headerLevel $prevHeaderLevel -}} {{- range seq (sub $prevHeaderLevel 1) -1 $headerLevel -}} {{- if in ($.Scratch.Get \u0026#34;bareul\u0026#34;) . -}} \u0026lt;/ul\u0026gt; {{/* manually do pop item */}} {{- $tmp := $.Scratch.Get \u0026#34;bareul\u0026#34; -}} {{- $.Scratch.Delete \u0026#34;bareul\u0026#34; -}} {{- $.Scratch.Set \u0026#34;bareul\u0026#34; slice}} {{- range seq (sub (len $tmp) 1) -}} {{- $.Scratch.Add \u0026#34;bareul\u0026#34; (index $tmp (sub . 1)) -}} {{- end -}} {{- else -}} \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; {{- end -}} {{- end -}} {{- end -}} {{- end }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#{{- $cleanedID -}}\u0026#34; aria-label=\u0026#34;{{- $header | plainify -}}\u0026#34;\u0026gt;{{- $header | safeHTML -}}\u0026lt;/a\u0026gt; {{- else }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#{{- $cleanedID -}}\u0026#34; aria-label=\u0026#34;{{- $header | plainify -}}\u0026#34;\u0026gt;{{- $header | safeHTML -}}\u0026lt;/a\u0026gt; {{- end -}} {{- end -}} \u0026lt;!-- {{- $firstHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers 0) 1) 0)) -}} --\u0026gt; {{- $firstHeaderLevel := $largest }} {{- $lastHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers (sub (len $headers) 1)) 1) 0)) }} \u0026lt;/li\u0026gt; {{- range seq (sub $lastHeaderLevel $firstHeaderLevel) -}} {{- if in ($.Scratch.Get \u0026#34;bareul\u0026#34;) (add . $firstHeaderLevel) }} \u0026lt;/ul\u0026gt; {{- else }} \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; {{- end -}} {{- end }} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/details\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/aside\u0026gt; \u0026lt;script\u0026gt; let activeElement; let elements; window.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, function (event) { checkTocPosition(); elements = document.querySelectorAll(\u0026#39;h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]\u0026#39;); // Make the first header active activeElement = elements[0]; const id = encodeURI(activeElement.getAttribute(\u0026#39;id\u0026#39;)).toLowerCase(); document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.add(\u0026#39;active\u0026#39;); }, false); window.addEventListener(\u0026#39;resize\u0026#39;, function(event) { checkTocPosition(); }, false); window.addEventListener(\u0026#39;scroll\u0026#39;, () =\u0026gt; { // Check if there is an object in the top half of the screen or keep the last item active activeElement = Array.from(elements).find((element) =\u0026gt; { if ((getOffsetTop(element) - window.pageYOffset) \u0026gt; 0 \u0026amp;\u0026amp; (getOffsetTop(element) - window.pageYOffset) \u0026lt; window.innerHeight/2) { return element; } }) || activeElement elements.forEach(element =\u0026gt; { const id = encodeURI(element.getAttribute(\u0026#39;id\u0026#39;)).toLowerCase(); if (element === activeElement){ document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.add(\u0026#39;active\u0026#39;); } else { document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.remove(\u0026#39;active\u0026#39;); } }) }, false); const main = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--article-width\u0026#39;), 10); const toc = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--toc-width\u0026#39;), 10); const gap = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--gap\u0026#39;), 10); function checkTocPosition() { const width = document.body.scrollWidth; if (width - main - (toc * 2) - (gap * 4) \u0026gt; 0) { document.getElementById(\u0026#34;toc-container\u0026#34;).classList.add(\u0026#34;wide\u0026#34;); } else { document.getElementById(\u0026#34;toc-container\u0026#34;).classList.remove(\u0026#34;wide\u0026#34;); } } function getOffsetTop(element) { if (!element.getClientRects().length) { return 0; } let rect = element.getBoundingClientRect(); let win = element.ownerDocument.defaultView; return rect.top + win.pageYOffset; } \u0026lt;/script\u0026gt; {{- end }} 2.找到目录 layouts/_default/single.html，调用toc.html，注意：这里默认是有调用的\n{{- if (.Param \u0026#34;ShowToc\u0026#34;) }} {{- partial \u0026#34;toc.html\u0026#34; . }} {{- end }} 3.修改css，找到目录 css/extended/blank.css ，复制如下代码\n:root { --nav-width: 1380px; --article-width: 650px; --toc-width: 300px; } .toc { margin: 0 2px 40px 2px; border: 1px solid var(--border); background: var(--entry); border-radius: var(--radius); padding: 0.4em; } .toc-container.wide { position: absolute; height: 100%; border-right: 1px solid var(--border); left: calc((var(--toc-width) + var(--gap)) * -1); top: calc(var(--gap) * 2); width: var(--toc-width); } .wide .toc { position: sticky; top: var(--gap); border: unset; background: unset; border-radius: unset; width: 100%; margin: 0 2px 40px 2px; } .toc details summary { cursor: zoom-in; margin-inline-start: 20px; padding: 12px 0; } .toc details[open] summary { font-weight: 500; } .toc-container.wide .toc .inner { margin: 0; } .active { font-size: 110%; font-weight: 600; } .toc ul { list-style-type: circle; } .toc .inner { margin: 0 0 0 20px; padding: 0px 15px 15px 20px; font-size: 16px; /*目录显示高度*/ max-height: 83vh; overflow-y: auto; } .toc .inner::-webkit-scrollbar-thumb { /*滚动条*/ background: var(--border); border: 7px solid var(--theme); border-radius: var(--radius); } .toc li ul { margin-inline-start: calc(var(--gap) * 0.5); list-style-type: none; } .toc li { list-style: none; font-size: 0.95rem; padding-bottom: 5px; } .toc li a:hover { color: var(--secondary); } 四.Git部署到Github 第一次部署到Github需要在yurooc目录下执行hugo命令生成public文件\ncd进入public文件之后，执行以下命令\ngit init #初始化仓库 git remote add origin https://github.com/yurooc/yurooc.github.io.git #链接远程仓库 git add . git commit -m \u0026#34;first commit\u0026#34; git branch -m master main #因为github远程仓库默认分支修改为main，而git本地分支为master，这里将本地分支master修改为main git push -f origin main\t#-f是全部覆盖，生产环境慎用此命令 在此之后更新文章，使用hugo生成新的静态页面，并使用git push进行同步 cd public git add . git status git commit -m \u0026#34;add blog post\u0026#34; git push -f origin main 五.域名解析，自定义域名 在华为云购买一个自己喜欢的域名，完成步骤之后在域名解析中修改记录集 主机记录：yurooc.top\n类型：CNAME\n值：yurooc.github.io\n然后到GitHub中的setting中找到Pages一栏，在Custom domain界面中填写自己的域名www.yurooc.top然后点击Save提交，等待几分钟后勾选Enforce HTTPS ","permalink":"https://yurooc.github.io/blog/hugo%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","summary":"一.Hugo中添加不蒜子计数 Hugo添加不蒜子页面浏览次数与阅读数据统计 什么是不蒜子？ Busuanzi是一个用于统计网站访问量的工具。它通常","title":"Hugo安装配置"},{"content":"Python基础库和三方库用法 1.Pandas 强大的数据分析工具\n用于数据分析，数据处理，数据可视化\n高性能 容易使用的数据结构 容易使用的数据分析工具 1.1Pandas数据读取 Pandas需要先读取表格类型的数据，然后进行分析\n数据类型 说明 Pandas读取方法 csv、tsv、txt 用逗号分隔、tab分割的纯文本文件 pd.read_csv() excel 微软xls或xlsx文件 pd.read_excel() mysql 关系型数据库表 pd.read_sql() 1.1.1示例（读取csv文件，使用默认的标题行、逗号分隔符）：\nfile_path = \u0026#39;文件路径\u0026#39; file_ = pa.read_csv(file_path)\t#使用pd.read_csv读取数据 file_.head()\t#查看前几行数据 file_.shape\t#查看数据的形状，返回(行数、列数) file_.columns\t#查看文件里的列名字段名列表 file_.index\t#查看文件数据索引列(有多少索引) file_.dtypes\t#查看每列的数据类型 1.1.2示例（读取txt文件，自己指定分隔符、列名）（txt文件格式不同，所以需要自己指定格式）：\npath = \u0026#34;路径\u0026#34; file = pd.read_csv( path, sep = \u0026#39;\\t\u0026#39;,\t#数据直接用什么分割，\\t代表换号符分割 header = None， #header代表标题行，这里None代表没有标题行，如果有标题列就进行设置 names =[\u0026#39;pdate\u0026#39;,\u0026#39;pv\u0026#39;,\u0026#39;uv\u0026#39;]\t#如果数据没有列名可以自己指定列名，这里用三个字段指定了三个列名 ) 1.1.3示例（读取excel文件）：\npath = \u0026#39;文件路径\u0026#39; file = pd.read_excel(path) 1.1.4示例（读取mysql数据表）：\nimport pymysql sql = pymysql.connect( host = \u0026#39;127.0.0.1\u0026#39;, uesr = \u0026#39;root\u0026#39;, password = \u0026#39;11111\u0026#39;, database = \u0026#39;test\u0026#39;, charset = \u0026#39;utf8\u0026#39; ) mysql_page = pd.read_sql(\u0026#39;select * from [表名]\u0026#39;,con=sql) mysql_page 1.2Pandas数据结构 1.2.1 DataFrame\n二维数据，整个表格，多行多列\n1.2.2 Series\n一维数据，一行或一列\n1.3Pandas查询数据 1.3.1查询数据的几种方法\ndf.loc(\u0026#39;索引\u0026#39;,\u0026#39;列名\u0026#39;)\t#根据行、列的索引进行查询 2.Numpy 3.OS ","permalink":"https://yurooc.github.io/blog/python%E5%9F%BA%E7%A1%80%E5%BA%93%E5%92%8C%E4%B8%89%E6%96%B9%E5%BA%93%E7%94%A8%E6%B3%95/","summary":"Python基础库和三方库用法 1.Pandas 强大的数据分析工具 用于数据分析，数据处理，数据可视化 高性能 容易使用的数据结构 容易使用的数据分析工具 1.1Pa","title":""}]